/**
 * Mock document data for development
 */
const mockDocuments = [
  {
    id: "doc1",
    title: "Improving Experimentation Techniques",
    uploadDate: "2025-05-25",
    fileType: "pdf",
    content: "# Improving Experimentation Techniques\n\n## Introduction\n\nExperimentation is the cornerstone of scientific progress and innovation in both academic research and industry applications. As we navigate the complexities of modern research challenges, the need for robust, efficient, and reliable experimentation techniques has never been more critical. This paper explores advanced methodologies for improving experimentation techniques across various disciplines, with a focus on enhancing reproducibility, statistical validity, and practical implementation.\n\n## The Current State of Experimentation\n\nTraditional experimentation approaches have served the scientific community well, but they face increasing scrutiny due to the replication crisis affecting multiple fields. Studies suggest that between 40-70% of published research findings cannot be replicated by independent researchers, raising concerns about the fundamental reliability of our knowledge base. This crisis stems from several factors:\n\n1. **Publication bias**: The tendency to publish positive results while neglecting negative findings\n2. **P-hacking**: The manipulation of data analysis to achieve statistically significant results\n3. **Underpowered studies**: Experiments with insufficient sample sizes to detect true effects\n4. **Poor experimental design**: Inadequate controls, randomization, or blinding procedures\n5. **Incomplete reporting**: Failure to document all relevant methodological details\n\nThese challenges necessitate a comprehensive reevaluation of how we design, conduct, and report experiments.\n\n## Principles of Robust Experimentation\n\n### Pre-registration and Registered Reports\n\nPre-registration involves publicly documenting the experimental design, hypotheses, and analysis plan before data collection begins. This approach prevents researchers from unconsciously or deliberately adjusting their analyses to find significant results. Registered reports take this concept further by having the experimental protocol peer-reviewed before the study is conducted, with publication guaranteed regardless of the outcome.\n\nBenefits of pre-registration include:\n- Reduction in publication bias\n- Clear distinction between confirmatory and exploratory analyses\n- Increased transparency in research methods\n- Greater confidence in reported findings\n\n### Statistical Power and Sample Size Determination\n\nUnderpowered studies waste resources and produce unreliable results. Modern experimentation techniques emphasize proper sample size calculations based on:\n\n- Expected effect size\n- Desired statistical power (typically 80% or higher)\n- Appropriate significance level\n- Study design considerations\n\nAdvanced power analysis tools now account for complex experimental designs, including nested structures, repeated measures, and multilevel models. Simulation-based approaches can provide more accurate estimates for non-standard designs where analytical solutions are unavailable.\n\n### Randomization and Blinding\n\nProper randomization eliminates systematic biases in treatment assignment, while blinding (masking) prevents observer bias from influencing results. Contemporary approaches include:\n\n- Computerized randomization algorithms\n- Stratified randomization to ensure balance across important covariates\n- Triple-blinding protocols (participants, experimenters, and data analysts remain unaware of treatment assignments)\n- Automated data collection systems that minimize human intervention\n\n## Advanced Experimental Designs\n\n### Factorial and Fractional Factorial Designs\n\nThese designs allow researchers to efficiently investigate multiple factors simultaneously, including their interactions. A full factorial design examines all possible combinations of factor levels, while fractional factorial designs strategically test a subset of these combinations to reduce resource requirements while maintaining the ability to detect main effects.\n\n### Adaptive Designs\n\nAdaptive experiments modify aspects of the study based on interim results, optimizing resource allocation and increasing the probability of detecting true effects. Examples include:\n\n- Group sequential designs that allow early stopping for efficacy or futility\n- Response-adaptive randomization that assigns more participants to promising treatments\n- Sample size re-estimation based on observed effect sizes\n- Adaptive enrichment designs that focus on responsive subpopulations\n\n### Crossover and N-of-1 Designs\n\nThese within-subject designs have participants receive multiple treatments in sequence, serving as their own controls. This approach reduces the impact of between-subject variability and can achieve greater statistical power with fewer participants. N-of-1 trials, which focus on individual treatment responses, are particularly valuable in personalized medicine and rare disease research.\n\n## Technological Innovations in Experimentation\n\n### Automation and High-Throughput Systems\n\nLaboratory automation has revolutionized experimentation by enabling:\n- Consistent execution of complex protocols\n- Parallel processing of multiple samples\n- Continuous operation without fatigue or human error\n- Integration with data management systems\n- Scalability for large-scale studies\n\nHigh-throughput screening platforms can test thousands of conditions simultaneously, dramatically accelerating discovery in fields like drug development, materials science, and genomics.\n\n### Digital Twins and Simulation\n\nDigital twins—virtual replicas of physical systems—allow researchers to conduct preliminary experiments in silico before committing resources to physical testing. Benefits include:\n- Rapid iteration of experimental designs\n- Exploration of parameter spaces too vast for physical testing\n- Identification of optimal experimental conditions\n- Prediction of system behaviors under various scenarios\n- Reduction in material waste and experimental costs\n\n### Machine Learning for Experimental Design\n\nMachine learning algorithms can optimize experimental designs by:\n- Identifying the most informative experiments to run next (active learning)\n- Detecting patterns in experimental data that suggest promising directions\n- Automating image analysis and other data processing tasks\n- Predicting experimental outcomes to guide resource allocation\n- Uncovering hidden variables affecting experimental results\n\n## Data Management and Analysis\n\n### Open Data and Code Sharing\n\nTransparent sharing of experimental data and analysis code enhances reproducibility and enables:\n- Independent verification of results\n- Meta-analyses combining multiple studies\n- Novel analyses of existing datasets\n- Collaborative improvement of analytical methods\n- Accelerated scientific progress through cumulative knowledge\n\n### Robust Statistical Methods\n\nModern statistical approaches address limitations of traditional methods:\n- Bayesian analysis provides intuitive probability statements about hypotheses\n- Robust statistics maintain validity despite violations of distributional assumptions\n- Multilevel models account for hierarchical data structures\n- Nonparametric methods avoid restrictive assumptions about data distributions\n- Multiple comparison corrections control false discovery rates in high-dimensional data\n\n## Conclusion\n\nImproving experimentation techniques requires a multifaceted approach that combines rigorous methodology, innovative design, advanced technology, and transparent reporting. By adopting these principles and practices, researchers can enhance the reliability, efficiency, and impact of their experimental work. As we continue to refine our approaches to experimentation, we strengthen the foundation of scientific knowledge and accelerate progress across disciplines.\n\nThe future of experimentation lies in adaptive, technology-enhanced approaches that maximize information gain while minimizing resource expenditure. By embracing these advances, the scientific community can address the replication crisis and usher in a new era of robust, reproducible research.",
    thumbnail: null,
    sourceType: "upload",
  },
  {
    id: "doc2",
    title: "Evolutionary Database Design Practices",
    uploadDate: "2025-05-25",
    fileType: "docx",
    content: "# Evolutionary Database Design Practices\n\n## Introduction\n\nDatabase design has traditionally followed a rigid, upfront planning approach where schemas are meticulously designed before implementation. However, as software development methodologies have evolved toward more agile and iterative processes, database design practices have needed to adapt accordingly. Evolutionary database design represents a paradigm shift that aligns database development with modern software engineering principles, enabling continuous delivery while maintaining data integrity and system performance.\n\nThis paper explores the principles, practices, and tools that support evolutionary database design, providing a comprehensive framework for implementing this approach in real-world scenarios.\n\n## The Need for Evolutionary Database Design\n\nTraditional database design methodologies often create bottlenecks in the development process for several reasons:\n\n1. **Resistance to change**: Once deployed, database schemas become difficult to modify without disrupting existing applications.\n2. **Incomplete requirements**: Initial requirements rarely capture all future needs, necessitating schema changes over time.\n3. **Technical debt accumulation**: Pressure to deliver features quickly can lead to suboptimal database designs that become increasingly problematic as the system grows.\n4. **Development-production disparity**: Differences between development and production environments can lead to unexpected issues during deployment.\n5. **Cross-team coordination challenges**: Database changes often require careful coordination between development, operations, and database administration teams.\n\nEvolutionary database design addresses these challenges by treating the database schema as a continuously evolving artifact rather than a fixed structure, enabling teams to respond to changing requirements while maintaining system stability.\n\n## Core Principles of Evolutionary Database Design\n\n### 1. Database as Code\n\nTreating database schemas as code involves:\n- Storing schema definitions in version control systems\n- Applying the same review processes to database changes as application code\n- Automating schema migrations through build and deployment pipelines\n- Testing database changes alongside application changes\n\nThis approach provides a historical record of schema evolution, facilitates collaboration, and enables automated testing and deployment of database changes.\n\n### 2. Incremental Change Management\n\nRather than making large, disruptive changes, evolutionary database design favors small, incremental modifications that:\n- Minimize risk by limiting the scope of each change\n- Allow for easier rollback if problems occur\n- Reduce the complexity of testing and validation\n- Enable continuous delivery of database changes\n\n### 3. Backward Compatibility\n\nMaintaining backward compatibility during schema evolution ensures that:\n- Existing applications continue to function during and after schema changes\n- Multiple versions of an application can operate against the same database\n- Deployments can be performed without downtime\n- Rollbacks remain possible if issues are discovered\n\n### 4. Automated Testing\n\nComprehensive testing of database changes includes:\n- Unit tests for stored procedures, functions, and triggers\n- Integration tests that verify schema changes work with application code\n- Performance tests to ensure changes don't degrade system responsiveness\n- Migration tests that validate the migration process itself\n\n### 5. Separation of Deployment from Release\n\nDecoupling deployment (installing new code/schema) from release (activating new features) through techniques like:\n- Feature toggles that allow new code paths to be enabled/disabled at runtime\n- Parallel change patterns where old and new schemas coexist during transition periods\n- Dark launches that test new features with production data before exposing them to users\n\n## Evolutionary Database Design Patterns\n\n### Expand and Contract Pattern\n\nThis pattern (also known as parallel change) involves three phases:\n1. **Expand**: Add new schema elements (tables, columns, etc.) while maintaining existing ones\n2. **Migrate**: Gradually move data and application code to use the new schema elements\n3. **Contract**: Remove the old schema elements once they're no longer needed\n\nThis approach allows for zero-downtime migrations by ensuring that applications can work with both old and new schemas during the transition period.\n\n### Database Refactoring\n\nDatabase refactoring involves making small, reversible changes to database schemas that improve design without changing semantics. Common refactorings include:\n- Renaming tables or columns\n- Splitting tables\n- Introducing lookup tables\n- Converting columns to new data types\n- Extracting common data into shared tables\n\nEach refactoring follows a specific pattern with defined steps for implementation and verification.\n\n### Feature Toggles for Database Changes\n\nFeature toggles allow teams to:\n- Deploy schema changes without immediately activating new functionality\n- Test new database features in production with limited exposure\n- Perform A/B testing of different schema designs\n- Quickly disable problematic features without rolling back schema changes\n\n### Blue-Green Database Deployments\n\nThis pattern involves maintaining two identical database environments:\n1. The currently active environment (blue)\n2. The environment receiving updates (green)\n\nAfter updates are applied and verified in the green environment, traffic is switched from blue to green. This approach minimizes downtime and provides a straightforward rollback mechanism.\n\n## Tools and Technologies Supporting Evolutionary Database Design\n\n### Database Migration Frameworks\n\nMigration frameworks provide structured approaches to managing schema changes:\n- **Flyway**: Java-based migration tool with SQL script versioning\n- **Liquibase**: XML, YAML, JSON, or SQL-based change management\n- **Alembic**: Python-based migration framework for SQLAlchemy\n- **Rails Migrations**: Ruby-based migration system for Ruby on Rails applications\n- **Entity Framework Migrations**: .NET-based migration system\n\nThese tools track which migrations have been applied, ensure they're applied in the correct order, and provide mechanisms for rolling back changes when necessary.\n\n### Database Version Control Integration\n\nModern version control systems can be extended to better support database artifacts:\n- Specialized diff tools that understand SQL semantics\n- Merge strategies optimized for database schema files\n- Hooks that validate database changes before committing\n- Integration with continuous integration systems to test database changes\n\n### Continuous Integration for Databases\n\nCI systems can be configured to:\n- Automatically create test databases with the latest schema\n- Run migration scripts against test databases\n- Execute database unit and integration tests\n- Perform schema comparison between different environments\n- Generate documentation from database schemas\n\n### Database Virtualization and Containerization\n\nVirtualization technologies enable:\n- Rapid provisioning of database environments for testing\n- Consistent database configurations across development, testing, and production\n- Isolated environments for testing schema changes\n- Snapshot and rollback capabilities for experimental changes\n\n## Implementation Strategies\n\n### Establishing a Database DevOps Pipeline\n\nA comprehensive database DevOps pipeline includes:\n1. **Development**: Local database environments for developers\n2. **Version Control**: Schema definitions and migration scripts in source control\n3. **Continuous Integration**: Automated testing of database changes\n4. **Deployment Automation**: Scripted, repeatable deployment processes\n5. **Monitoring**: Runtime observation of database performance and behavior\n\n### Handling Legacy Databases\n\nTransitioning legacy databases to an evolutionary approach involves:\n- Creating a baseline schema definition from the current state\n- Implementing version control for future changes\n- Gradually introducing automated tests\n- Refactoring problematic areas incrementally\n- Establishing deployment pipelines for database changes\n\n### Managing Database Dependencies\n\nComplex systems often involve multiple databases with interdependencies. Strategies for managing these include:\n- Clearly defined interfaces between database components\n- Versioned database APIs (views, stored procedures)\n- Compatibility layers that support multiple versions\n- Coordinated but independent release cycles\n\n### Data Migration Strategies\n\nMoving data during schema evolution requires careful planning:\n- Batch migration for large datasets during maintenance windows\n- Incremental migration for systems requiring high availability\n- Dual-write approaches during transition periods\n- Read-repair strategies that migrate data on access\n\n## Case Studies\n\n### E-commerce Platform Evolution\n\nA large e-commerce company successfully implemented evolutionary database design by:\n- Breaking their monolithic database into domain-specific services\n- Implementing a database migration framework with automated testing\n- Using feature toggles to control the activation of new schema features\n- Adopting a microservice architecture with database-per-service\n- Implementing CDC (Change Data Capture) for cross-service data synchronization\n\nThe result was a 75% reduction in deployment-related incidents and a 3x increase in release frequency.\n\n### Financial System Modernization\n\nA banking system modernized their legacy database infrastructure by:\n- Creating a comprehensive test suite for existing functionality\n- Implementing an expand-and-contract approach for schema changes\n- Gradually replacing stored procedures with application code\n- Using database sharding to improve scalability\n- Implementing blue-green deployments for zero-downtime updates\n\nThis approach allowed them to maintain 24/7 availability while completely restructuring their data model over an 18-month period.\n\n## Conclusion\n\nEvolutionary database design represents a fundamental shift in how we approach database development, aligning database practices with modern software engineering principles. By treating database schemas as evolving artifacts rather than fixed structures, organizations can achieve greater agility, reliability, and maintainability in their data systems.\n\nThe key to successful implementation lies in adopting appropriate tools, patterns, and practices that support incremental change while maintaining system stability. As database technologies continue to evolve, the principles of evolutionary design will remain relevant, enabling teams to deliver value continuously while managing the complexity inherent in database systems.\n\nBy embracing these practices, organizations can transform their database development from a bottleneck into a competitive advantage, enabling faster innovation while maintaining the integrity and performance of their data systems.",
    thumbnail: null,
    sourceType: "upload",
  },
  {
    id: "doc3",
    title: "Machine Learning Fundamentals",
    uploadDate: "2025-05-24",
    fileType: "pdf",
    content: "# Machine Learning Fundamentals\n\n## Introduction\n\nMachine learning (ML) has emerged as one of the most transformative technologies of the 21st century, revolutionizing industries from healthcare and finance to transportation and entertainment. At its core, machine learning enables computers to learn from data and improve their performance on specific tasks without being explicitly programmed. This paper provides a comprehensive overview of machine learning fundamentals, covering key concepts, algorithms, methodologies, and practical considerations for implementation.\n\n## The Learning Paradigm\n\nUnlike traditional programming where explicit rules are coded to solve problems, machine learning systems derive rules from data. This paradigm shift offers several advantages:\n\n1. **Adaptability**: ML systems can adjust to changing environments and data patterns\n2. **Scalability**: They can handle problems too complex for manual programming\n3. **Discovery**: They can identify patterns and relationships not obvious to human observers\n4. **Automation**: They can perform tasks that would otherwise require human intelligence\n\nThe learning process typically involves:\n- Collecting and preparing relevant data\n- Selecting an appropriate algorithm or model\n- Training the model on historical data\n- Evaluating performance using metrics relevant to the problem domain\n- Deploying the model to make predictions on new data\n- Monitoring and updating the model as needed\n\n## Types of Machine Learning\n\n### Supervised Learning\n\nIn supervised learning, models are trained on labeled data, where each example consists of input features and the corresponding correct output. The model learns to map inputs to outputs, enabling it to make predictions on new, unseen data.\n\nCommon supervised learning tasks include:\n\n**Classification**: Predicting categorical labels (e.g., spam detection, image recognition)\n- Binary classification: Two possible classes (e.g., benign vs. malignant)\n- Multi-class classification: More than two mutually exclusive classes (e.g., digit recognition)\n- Multi-label classification: Multiple non-exclusive labels per instance (e.g., topic tagging)\n\n**Regression**: Predicting continuous values (e.g., house prices, temperature forecasting)\n- Linear regression: Modeling linear relationships between inputs and outputs\n- Polynomial regression: Capturing non-linear relationships using polynomial functions\n- Multiple regression: Using multiple input variables to predict the output\n\nPopular supervised learning algorithms include:\n- Linear and logistic regression\n- Decision trees and random forests\n- Support vector machines (SVMs)\n- k-Nearest Neighbors (k-NN)\n- Neural networks and deep learning\n\n### Unsupervised Learning\n\nUnsupervised learning involves training models on unlabeled data, allowing them to discover hidden patterns or structures without explicit guidance.\n\nKey unsupervised learning tasks include:\n\n**Clustering**: Grouping similar instances together\n- K-means clustering: Partitioning data into k distinct clusters\n- Hierarchical clustering: Building nested clusters in a tree-like structure\n- Density-based clustering: Identifying clusters as dense regions separated by sparse areas\n\n**Dimensionality Reduction**: Simplifying data while preserving important information\n- Principal Component Analysis (PCA): Transforming data to linearly uncorrelated variables\n- t-Distributed Stochastic Neighbor Embedding (t-SNE): Visualizing high-dimensional data\n- Autoencoders: Neural networks that learn compressed representations of data\n\n**Anomaly Detection**: Identifying unusual patterns that don't conform to expected behavior\n- Statistical methods: Using statistical tests to identify outliers\n- Isolation Forest: Isolating anomalies through random partitioning\n- One-class SVM: Learning the boundary of normal data\n\n### Reinforcement Learning\n\nReinforcement learning involves training agents to make sequences of decisions by rewarding desired behaviors and penalizing undesired ones. The agent learns to maximize cumulative rewards through trial and error.\n\nKey components of reinforcement learning include:\n- **Agent**: The decision-maker that interacts with the environment\n- **Environment**: The world in which the agent operates\n- **State**: The current situation of the agent\n- **Action**: The possible moves the agent can make\n- **Reward**: The feedback from the environment after an action\n- **Policy**: The strategy the agent uses to determine actions\n\nPopular reinforcement learning algorithms include:\n- Q-Learning: Learning the value of actions in different states\n- Deep Q-Networks (DQN): Combining Q-learning with deep neural networks\n- Policy Gradient Methods: Directly optimizing the policy\n- Actor-Critic Methods: Combining value function estimation with policy optimization\n\n### Semi-Supervised Learning\n\nSemi-supervised learning combines elements of supervised and unsupervised learning, using a small amount of labeled data along with a larger amount of unlabeled data. This approach is particularly valuable when labeled data is scarce or expensive to obtain.\n\nTechniques in semi-supervised learning include:\n- Self-training: Using a model's own predictions on unlabeled data to augment training\n- Co-training: Training multiple models on different views of the data\n- Graph-based methods: Propagating labels through a similarity graph of instances\n\n## Feature Engineering and Selection\n\nFeature engineering—the process of creating, transforming, and selecting relevant features—is crucial for model performance.\n\n### Feature Creation\n\nCreating informative features may involve:\n- Domain knowledge to identify relevant attributes\n- Mathematical transformations (e.g., logarithmic, polynomial)\n- Interaction terms to capture relationships between features\n- Temporal features from time-series data (e.g., day of week, seasonality)\n- Text features from natural language (e.g., bag-of-words, TF-IDF, word embeddings)\n\n### Feature Transformation\n\nTransforming features can improve model performance through:\n- Normalization: Scaling features to a standard range (e.g., [0,1])\n- Standardization: Transforming features to have zero mean and unit variance\n- Binning: Converting continuous variables into categorical bins\n- Encoding: Converting categorical variables into numerical representations\n- Power transformations: Stabilizing variance and making distributions more normal\n\n### Feature Selection\n\nSelecting the most relevant features helps to:\n- Reduce overfitting by eliminating noise\n- Improve model interpretability\n- Reduce computational requirements\n- Address the curse of dimensionality\n\nMethods for feature selection include:\n- Filter methods: Selecting features based on statistical measures\n- Wrapper methods: Evaluating feature subsets using the model itself\n- Embedded methods: Incorporating feature selection into the model training process\n\n## Model Evaluation and Validation\n\nProper evaluation is essential for assessing model performance and generalization ability.\n\n### Performance Metrics\n\nDifferent metrics are appropriate for different types of problems:\n\n**Classification Metrics**:\n- Accuracy: Proportion of correct predictions\n- Precision: Proportion of positive identifications that are correct\n- Recall (Sensitivity): Proportion of actual positives correctly identified\n- F1 Score: Harmonic mean of precision and recall\n- Area Under the ROC Curve (AUC): Measuring discrimination ability\n- Confusion Matrix: Tabulating predicted vs. actual class assignments\n\n**Regression Metrics**:\n- Mean Absolute Error (MAE): Average absolute differences between predictions and actuals\n- Mean Squared Error (MSE): Average squared differences\n- Root Mean Squared Error (RMSE): Square root of MSE\n- R-squared: Proportion of variance explained by the model\n- Mean Absolute Percentage Error (MAPE): Average percentage differences\n\n### Validation Techniques\n\nProper validation helps estimate how well models will perform on unseen data:\n\n- Train-Test Split: Dividing data into training and testing sets\n- Cross-Validation: Partitioning data into multiple folds for training and validation\n- Stratified Sampling: Maintaining class distribution in splits\n- Time-Series Validation: Respecting temporal order in time-series data\n- Holdout Validation: Setting aside a separate dataset for final evaluation\n\n### Bias-Variance Tradeoff\n\nUnderstanding the bias-variance tradeoff is crucial for model selection and tuning:\n- **Bias**: Error from oversimplified assumptions in the learning algorithm\n- **Variance**: Error from sensitivity to small fluctuations in the training set\n- **Underfitting**: High bias, low variance (model too simple)\n- **Overfitting**: Low bias, high variance (model too complex)\n\nTechniques to address this tradeoff include:\n- Regularization: Adding penalties to model complexity\n- Ensemble methods: Combining multiple models to reduce overall error\n- Cross-validation: Properly assessing generalization performance\n\n## Deep Learning\n\nDeep learning, a subset of machine learning based on artificial neural networks, has achieved remarkable success in various domains.\n\n### Neural Network Fundamentals\n\nBasic components of neural networks include:\n- **Neurons**: Computational units that apply activation functions to weighted inputs\n- **Layers**: Collections of neurons (input, hidden, and output layers)\n- **Weights and Biases**: Parameters learned during training\n- **Activation Functions**: Non-linear functions that introduce complexity (e.g., ReLU, sigmoid, tanh)\n- **Loss Functions**: Measures of prediction error to be minimized\n\n### Deep Learning Architectures\n\nSpecialized architectures address different problem domains:\n\n- **Convolutional Neural Networks (CNNs)**: Designed for grid-like data such as images\n  - Convolutional layers: Applying filters to detect local patterns\n  - Pooling layers: Reducing spatial dimensions while preserving important features\n  - Applications: Image classification, object detection, segmentation\n\n- **Recurrent Neural Networks (RNNs)**: Processing sequential data\n  - Feedback connections: Allowing information persistence\n  - Long Short-Term Memory (LSTM): Addressing the vanishing gradient problem\n  - Gated Recurrent Units (GRU): Simplified version of LSTM\n  - Applications: Natural language processing, time-series analysis, speech recognition\n\n- **Transformers**: Handling sequential data with attention mechanisms\n  - Self-attention: Weighing the importance of different parts of the input\n  - Parallelization: Processing sequences simultaneously rather than sequentially\n  - Applications: Language models (e.g., BERT, GPT), machine translation\n\n- **Generative Adversarial Networks (GANs)**: Creating new data instances\n  - Generator: Producing synthetic samples\n  - Discriminator: Distinguishing real from synthetic samples\n  - Applications: Image generation, data augmentation, style transfer\n\n### Deep Learning Challenges\n\nDespite their success, deep learning systems face several challenges:\n- Data hunger: Requiring large amounts of training data\n- Computational intensity: Demanding significant processing power\n- Black-box nature: Lacking interpretability\n- Adversarial vulnerability: Susceptibility to specially crafted inputs\n\n## Practical Considerations\n\n### Data Preprocessing\n\nEffective preprocessing is crucial for model performance:\n- Handling missing values through imputation or deletion\n- Addressing outliers through transformation or removal\n- Balancing class distributions in imbalanced datasets\n- Normalizing or standardizing numerical features\n- Encoding categorical variables appropriately\n\n### Hyperparameter Tuning\n\nOptimizing model hyperparameters involves:\n- Grid search: Exhaustively searching through a specified parameter grid\n- Random search: Sampling parameters from specified distributions\n- Bayesian optimization: Using probabilistic models to guide the search\n- Genetic algorithms: Evolving parameter sets through selection and mutation\n\n### Model Deployment\n\nDeploying models to production environments requires:\n- Model serialization and versioning\n- Scalable inference infrastructure\n- Monitoring for performance degradation\n- Strategies for model updates and retraining\n- Integration with existing systems and workflows\n\n### Ethical Considerations\n\nResponsible ML implementation must address:\n- Bias and fairness in model predictions\n- Privacy concerns in data collection and usage\n- Transparency and explainability of model decisions\n- Security vulnerabilities in ML systems\n- Societal impacts of automated decision-making\n\n## Conclusion\n\nMachine learning fundamentals provide the foundation for developing systems that can learn from data and improve with experience. By understanding the different learning paradigms, algorithms, evaluation methods, and practical considerations, practitioners can effectively apply machine learning to solve complex problems across diverse domains.\n\nAs the field continues to evolve, staying grounded in these fundamentals while embracing new advances will be essential for harnessing the full potential of machine learning. The journey from data to intelligent systems requires not only technical expertise but also careful consideration of the broader implications of automated decision-making in our increasingly data-driven world.",
    thumbnail: null,
    sourceType: "upload",
  },
  {
    id: "doc4",
    title: "Introduction to React Hooks",
    uploadDate: "2025-05-23",
    fileType: "md",
    content: "# Introduction to React Hooks\n\n## The Evolution of React Component Patterns\n\nReact has revolutionized front-end development since its introduction in 2013, providing a component-based architecture that enables developers to build complex user interfaces with reusable, composable pieces. The evolution of React component patterns reflects the community's ongoing quest for more elegant, maintainable, and performant code.\n\n### Class Components: The Traditional Approach\n\nInitially, React offered two types of components: functional components (also called stateless components) and class components. Class components, extending from React.Component, were the workhorses of React applications for several years:\n\n```jsx\nclass Counter extends React.Component {\n  constructor(props) {\n    super(props);\n    this.state = { count: 0 };\n    this.increment = this.increment.bind(this);\n  }\n\n  increment() {\n    this.setState({ count: this.state.count + 1 });\n  }\n\n  componentDidMount() {\n    document.title = `Count: ${this.state.count}`;\n  }\n\n  componentDidUpdate() {\n    document.title = `Count: ${this.state.count}`;\n  }\n\n  render() {\n    return (\n      <div>\n        <p>Count: {this.state.count}</p>\n        <button onClick={this.increment}>Increment</button>\n      </div>\n    );\n  }\n}\n```\n\nWhile powerful, class components presented several challenges:\n\n1. **Verbose syntax**: Requiring constructors, binding methods, and extending React.Component\n2. **Complex lifecycle methods**: Managing component mounting, updating, and unmounting\n3. **\"this\" binding issues**: Causing confusion, especially for developers new to JavaScript\n4. **Logic reuse limitations**: Making it difficult to share stateful logic between components\n5. **Large component files**: Often resulting in \"giant components\" that were difficult to maintain\n\n### Higher-Order Components and Render Props\n\nTo address the challenge of sharing logic between components, the React community developed patterns like Higher-Order Components (HOCs) and render props:\n\n**Higher-Order Components**:\n```jsx\n// A HOC that adds window size tracking to any component\nfunction withWindowSize(WrappedComponent) {\n  return class extends React.Component {\n    constructor(props) {\n      super(props);\n      this.state = { width: window.innerWidth, height: window.innerHeight };\n      this.handleResize = this.handleResize.bind(this);\n    }\n\n    handleResize() {\n      this.setState({ width: window.innerWidth, height: window.innerHeight });\n    }\n\n    componentDidMount() {\n      window.addEventListener('resize', this.handleResize);\n    }\n\n    componentWillUnmount() {\n      window.removeEventListener('resize', this.handleResize);\n    }\n\n    render() {\n      return <WrappedComponent {...this.props} windowSize={this.state} />;\n    }\n  };\n}\n\n// Usage\nconst MyComponentWithWindowSize = withWindowSize(MyComponent);\n```\n\n**Render Props**:\n```jsx\nclass WindowSize extends React.Component {\n  constructor(props) {\n    super(props);\n    this.state = { width: window.innerWidth, height: window.innerHeight };\n    this.handleResize = this.handleResize.bind(this);\n  }\n\n  handleResize() {\n    this.setState({ width: window.innerWidth, height: window.innerHeight });\n  }\n\n  componentDidMount() {\n    window.addEventListener('resize', this.handleResize);\n  }\n\n  componentWillUnmount() {\n    window.removeEventListener('resize', this.handleResize);\n  }\n\n  render() {\n    return this.props.children(this.state);\n  }\n}\n\n// Usage\n<WindowSize>\n  {size => <div>Window width: {size.width}, height: {size.height}</div>}\n</WindowSize>\n```\n\nWhile these patterns improved code reuse, they introduced their own challenges:\n\n1. **Wrapper hell**: Deeply nested component hierarchies that were difficult to follow\n2. **Naming collisions**: Props from different HOCs potentially overwriting each other\n3. **Cognitive overhead**: Requiring developers to understand complex patterns\n4. **Runtime performance**: Adding extra components to the React component tree\n\n## Enter React Hooks: A Paradigm Shift\n\nReact Hooks, introduced in React 16.8 (February 2019), represent a fundamental shift in how developers write React components. Hooks allow functional components to use state, lifecycle methods, context, and other React features previously available only in class components.\n\n### Core Benefits of Hooks\n\n1. **Simplicity**: Reducing boilerplate and allowing more concise component code\n2. **Composability**: Enabling better composition and reuse of stateful logic\n3. **Readability**: Organizing code by logical concerns rather than lifecycle methods\n4. **Testability**: Making components easier to test due to reduced complexity\n5. **Performance optimizations**: Providing fine-grained control over re-renders\n\n### The Core Hooks\n\n#### useState: Managing Local Component State\n\nThe useState hook provides a way to add state to functional components:\n\n```jsx\nimport React, { useState } from 'react';\n\nfunction Counter() {\n  const [count, setCount] = useState(0);\n\n  return (\n    <div>\n      <p>Count: {count}</p>\n      <button onClick={() => setCount(count + 1)}>Increment</button>\n    </div>\n  );\n}\n```\n\nKey aspects of useState:\n- Returns a state value and a function to update it\n- Takes an initial state value as its argument\n- Can be called multiple times for multiple state variables\n- Preserves state between re-renders\n- Updates trigger re-renders, just like setState in class components\n\n#### useEffect: Handling Side Effects\n\nThe useEffect hook handles side effects in functional components, replacing several lifecycle methods:\n\n```jsx\nimport React, { useState, useEffect } from 'react';\n\nfunction DocumentTitleCounter() {\n  const [count, setCount] = useState(0);\n\n  useEffect(() => {\n    document.title = `Count: ${count}`;\n    // Optional cleanup function\n    return () => {\n      document.title = 'React App';\n    };\n  }, [count]); // Dependency array\n\n  return (\n    <div>\n      <p>Count: {count}</p>\n      <button onClick={() => setCount(count + 1)}>Increment</button>\n    </div>\n  );\n}\n```\n\nKey aspects of useEffect:\n- Runs after render, combining componentDidMount and componentDidUpdate\n- Can return a cleanup function (similar to componentWillUnmount)\n- Uses a dependency array to control when the effect runs\n- Can be used multiple times for different effects\n- Helps separate concerns by grouping related code\n\n#### useContext: Consuming Context\n\nThe useContext hook provides a simpler way to consume React context:\n\n```jsx\nimport React, { useContext } from 'react';\nimport { ThemeContext } from './ThemeContext';\n\nfunction ThemedButton() {\n  const theme = useContext(ThemeContext);\n  \n  return (\n    <button style={{ background: theme.background, color: theme.foreground }}>\n      Styled by theme context\n    </button>\n  );\n}\n```\n\nKey aspects of useContext:\n- Accepts a context object created by React.createContext\n- Returns the current context value\n- Always re-renders when the context value changes\n- Simplifies context consumption compared to Context.Consumer\n\n#### useReducer: Complex State Logic\n\nThe useReducer hook manages complex state logic using a reducer pattern:\n\n```jsx\nimport React, { useReducer } from 'react';\n\n// Reducer function\nfunction counterReducer(state, action) {\n  switch (action.type) {\n    case 'increment':\n      return { count: state.count + 1 };\n    case 'decrement':\n      return { count: state.count - 1 };\n    case 'reset':\n      return { count: 0 };\n    default:\n      throw new Error(`Unsupported action type: ${action.type}`);\n  }\n}\n\nfunction Counter() {\n  const [state, dispatch] = useReducer(counterReducer, { count: 0 });\n\n  return (\n    <div>\n      <p>Count: {state.count}</p>\n      <button onClick={() => dispatch({ type: 'increment' })}>Increment</button>\n      <button onClick={() => dispatch({ type: 'decrement' })}>Decrement</button>\n      <button onClick={() => dispatch({ type: 'reset' })}>Reset</button>\n    </div>\n  );\n}\n```\n\nKey aspects of useReducer:\n- Alternative to useState for complex state logic\n- Follows the Redux-like pattern of actions and reducers\n- Provides more predictable state transitions\n- Helps manage related state transitions together\n- Useful when next state depends on previous state\n\n#### useCallback and useMemo: Performance Optimization\n\nThese hooks help optimize performance by memoizing functions and values:\n\n```jsx\nimport React, { useState, useCallback, useMemo } from 'react';\n\nfunction ExpensiveCalculation({ a, b }) {\n  // Memoize expensive calculation\n  const result = useMemo(() => {\n    console.log('Computing result...');\n    return a * b * 1000000000;\n  }, [a, b]);\n\n  // Memoize event handler\n  const handleClick = useCallback(() => {\n    console.log(`The result is ${result}`);\n  }, [result]);\n\n  return (\n    <div>\n      <p>Result: {result}</p>\n      <button onClick={handleClick}>Log Result</button>\n    </div>\n  );\n}\n```\n\nKey aspects:\n- **useCallback**: Returns a memoized callback that only changes if dependencies change\n- **useMemo**: Returns a memoized value that only recalculates when dependencies change\n- Both help prevent unnecessary re-renders and calculations\n- Critical for optimizing performance in complex components\n\n#### useRef: Accessing DOM Elements and Persisting Values\n\nThe useRef hook provides a way to access DOM elements and persist values between renders:\n\n```jsx\nimport React, { useRef, useEffect } from 'react';\n\nfunction TextInputWithFocusButton() {\n  const inputRef = useRef(null);\n  \n  function handleClick() {\n    inputRef.current.focus();\n  }\n\n  return (\n    <div>\n      <input ref={inputRef} type=\"text\" />\n      <button onClick={handleClick}>Focus the input</button>\n    </div>\n  );\n}\n```\n\nKey aspects of useRef:\n- Creates a mutable ref object with a .current property\n- Persists between renders (unlike regular variables)\n- Doesn't cause re-renders when its value changes\n- Commonly used for DOM references and storing previous values\n\n### Custom Hooks: Reusing Stateful Logic\n\nOne of the most powerful aspects of Hooks is the ability to create custom hooks, enabling stateful logic reuse without changing component hierarchy:\n\n```jsx\n// Custom hook for window size\nfunction useWindowSize() {\n  const [windowSize, setWindowSize] = useState({\n    width: window.innerWidth,\n    height: window.innerHeight\n  });\n\n  useEffect(() => {\n    function handleResize() {\n      setWindowSize({\n        width: window.innerWidth,\n        height: window.innerHeight\n      });\n    }\n\n    window.addEventListener('resize', handleResize);\n    return () => window.removeEventListener('resize', handleResize);\n  }, []);\n\n  return windowSize;\n}\n\n// Usage in components\nfunction MyComponent() {\n  const size = useWindowSize();\n  return <div>Window width: {size.width}, height: {size.height}</div>;\n}\n```\n\nCustom hooks:\n- Start with \"use\" by convention\n- Can call other hooks\n- Enable sharing stateful logic between components\n- Keep components clean and focused on rendering\n- Create a new ecosystem of reusable logic\n\n## Rules of Hooks\n\nTo ensure hooks work correctly, React enforces two important rules:\n\n1. **Only call hooks at the top level**: Don't call hooks inside loops, conditions, or nested functions\n2. **Only call hooks from React functions**: Call hooks from React functional components or custom hooks\n\nThese rules ensure that hooks maintain their state correctly between renders. The React team provides an ESLint plugin (eslint-plugin-react-hooks) to enforce these rules automatically.\n\n## Advanced Hook Patterns\n\n### State Management with Context and Reducers\n\nCombining useContext and useReducer creates a powerful state management solution:\n\n```jsx\n// Create context\nconst TodoContext = React.createContext();\n\n// Create provider component\nfunction TodoProvider({ children }) {\n  const [todos, dispatch] = useReducer(todoReducer, initialTodos);\n  \n  return (\n    <TodoContext.Provider value={{ todos, dispatch }}>\n      {children}\n    </TodoContext.Provider>\n  );\n}\n\n// Custom hook to use the todo context\nfunction useTodos() {\n  const context = useContext(TodoContext);\n  if (!context) {\n    throw new Error('useTodos must be used within a TodoProvider');\n  }\n  return context;\n}\n\n// Usage in components\nfunction TodoList() {\n  const { todos, dispatch } = useTodos();\n  \n  return (\n    <ul>\n      {todos.map(todo => (\n        <li key={todo.id}>\n          {todo.text}\n          <button onClick={() => dispatch({ type: 'REMOVE', id: todo.id })}>\n            Delete\n          </button>\n        </li>\n      ))}\n    </ul>\n  );\n}\n```\n\nThis pattern:\n- Provides a Redux-like state management solution\n- Avoids prop drilling through component hierarchies\n- Keeps related state and logic together\n- Scales well for medium-sized applications\n\n### Abstracting Complex Logic with Custom Hooks\n\nCustom hooks can abstract complex logic into reusable units:\n\n```jsx\n// Hook for API data fetching with loading and error states\nfunction useApi(url) {\n  const [data, setData] = useState(null);\n  const [loading, setLoading] = useState(true);\n  const [error, setError] = useState(null);\n\n  useEffect(() => {\n    let isMounted = true;\n    \n    async function fetchData() {\n      try {\n        setLoading(true);\n        const response = await fetch(url);\n        if (!response.ok) throw new Error('Network response was not ok');\n        const result = await response.json();\n        \n        if (isMounted) {\n          setData(result);\n          setError(null);\n        }\n      } catch (err) {\n        if (isMounted) {\n          setError(err.message);\n          setData(null);\n        }\n      } finally {\n        if (isMounted) {\n          setLoading(false);\n        }\n      }\n    }\n\n    fetchData();\n    \n    return () => {\n      isMounted = false;\n    };\n  }, [url]);\n\n  return { data, loading, error };\n}\n\n// Usage\nfunction UserProfile({ userId }) {\n  const { data: user, loading, error } = useApi(`/api/users/${userId}`);\n  \n  if (loading) return <div>Loading...</div>;\n  if (error) return <div>Error: {error}</div>;\n  \n  return (\n    <div>\n      <h1>{user.name}</h1>\n      <p>Email: {user.email}</p>\n    </div>\n  );\n}\n```\n\nThis approach:\n- Encapsulates complex async logic\n- Handles common concerns like loading states and error handling\n- Makes components cleaner and more focused\n- Enables consistent patterns across the application\n\n## Migrating to Hooks\n\nFor existing React applications, migrating to hooks typically follows these steps:\n\n1. **Update React version**: Ensure you're using React 16.8 or later\n2. **Gradual migration**: Convert components one at a time, starting with simpler ones\n3. **Identify stateful logic**: Look for opportunities to extract custom hooks\n4. **Refactor class components**: Convert to functional components with hooks\n5. **Update tests**: Adjust tests to work with the new component structure\n\nBest practices for migration:\n- Don't rewrite everything at once\n- Start with new components using hooks\n- Convert class components when making other changes\n- Use the React DevTools Profiler to verify performance\n- Consider codemods for automated conversions\n\n## Hooks in the React Ecosystem\n\nHooks have been widely adopted across the React ecosystem:\n\n- **React Router**: Uses hooks like useParams, useLocation, and useHistory\n- **Redux**: Provides useSelector and useDispatch hooks\n- **React Query**: Built entirely around hooks for data fetching\n- **Formik**: Offers useFormik hook for form management\n- **React Spring**: Uses hooks for animations\n\nThis widespread adoption demonstrates how hooks have become the preferred way to write React components and share logic in the ecosystem.\n\n## Conclusion\n\nReact Hooks represent a significant evolution in how React components are written and composed. By enabling functional components to use state and other React features, hooks simplify component code, improve reusability, and provide a more intuitive mental model for React development.\n\nThe introduction of hooks has led to cleaner, more maintainable code and has spawned an ecosystem of reusable logic that continues to grow. As React continues to evolve, hooks remain at the center of modern React development, empowering developers to write more expressive, composable, and maintainable applications.\n\nWhether you're building a new React application or maintaining an existing one, understanding and leveraging hooks is essential for effective React development in today's ecosystem.",
    thumbnail: null,
    sourceType: "upload",
  },
  {
    id: "doc5",
    title: "Advanced CSS Techniques",
    uploadDate: "2025-05-22",
    fileType: "txt",
    content: "# Advanced CSS Techniques\n\n## Introduction\n\nCascading Style Sheets (CSS) has evolved dramatically since its introduction in 1996. What began as a simple mechanism for styling HTML documents has grown into a powerful language capable of creating complex layouts, animations, and interactive experiences. This paper explores advanced CSS techniques that push the boundaries of what's possible in modern web development, focusing on methodologies that enhance performance, maintainability, and user experience.\n\n## Modern Layout Systems\n\n### CSS Grid Layout\n\nCSS Grid Layout represents a paradigm shift in how we approach web layouts. Unlike earlier techniques that relied on floats or positioning, Grid provides a two-dimensional system designed specifically for creating complex, responsive layouts.\n\n#### Key Concepts\n\n**Grid Container and Grid Items**:\nThe grid container is the element on which `display: grid` is applied, while its direct children become grid items. This parent-child relationship establishes the grid context:\n\n```css\n.container {\n  display: grid;\n  grid-template-columns: repeat(3, 1fr);\n  grid-template-rows: auto 1fr auto;\n  gap: 20px;\n}\n```\n\n**Explicit vs. Implicit Grid**:\nThe explicit grid is defined through properties like `grid-template-columns` and `grid-template-rows`, while the implicit grid is automatically generated when content exceeds the defined grid:\n\n```css\n.container {\n  display: grid;\n  grid-template-columns: repeat(3, 1fr); /* Explicit columns */\n  grid-auto-rows: minmax(100px, auto); /* Implicit rows */\n}\n```\n\n**Grid Lines and Grid Areas**:\nGrid lines form the structure of the grid, while grid areas are rectangular spaces surrounded by four grid lines. Named grid areas provide an intuitive way to define layouts:\n\n```css\n.container {\n  display: grid;\n  grid-template-areas:\n    \"header header header\"\n    \"sidebar content content\"\n    \"footer footer footer\";\n  grid-template-columns: 1fr 3fr;\n  grid-template-rows: auto 1fr auto;\n}\n\n.header { grid-area: header; }\n.sidebar { grid-area: sidebar; }\n.content { grid-area: content; }\n.footer { grid-area: footer; }\n```\n\n#### Advanced Grid Techniques\n\n**Responsive Layouts Without Media Queries**:\nUsing functions like `minmax()`, `auto-fill`, and `auto-fit` allows for responsive designs without traditional breakpoints:\n\n```css\n.container {\n  display: grid;\n  grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));\n  gap: 20px;\n}\n```\n\nThis creates a layout where columns automatically adjust based on available space, with each column being at least 250px wide and sharing available space equally.\n\n**Masonry-Like Layouts**:\nWhile true masonry layouts are challenging with pure CSS, Grid can create similar effects using `grid-auto-flow: dense` to fill gaps:\n\n```css\n.gallery {\n  display: grid;\n  grid-template-columns: repeat(auto-fill, minmax(200px, 1fr));\n  grid-auto-rows: 200px;\n  grid-auto-flow: dense;\n  gap: 10px;\n}\n\n.gallery-item.wide {\n  grid-column: span 2;\n}\n\n.gallery-item.tall {\n  grid-row: span 2;\n}\n```\n\n**Subgrid**:\nThe subgrid feature (part of CSS Grid Level 2) allows grid items that are also grid containers to inherit grid tracks from their parents:\n\n```css\n.container {\n  display: grid;\n  grid-template-columns: repeat(9, 1fr);\n  gap: 10px;\n}\n\n.item {\n  grid-column: span 3;\n  display: grid;\n  grid-template-columns: subgrid;\n}\n```\n\nThis enables complex nested layouts while maintaining alignment with the parent grid.\n\n### Flexbox\n\nWhile Grid excels at two-dimensional layouts, Flexbox provides powerful tools for one-dimensional layouts, particularly for distributing space and aligning items within a container.\n\n#### Advanced Flexbox Patterns\n\n**Holy Grail Layout**:\nThe classic \"holy grail\" layout (header, footer, and three columns) can be implemented elegantly with Flexbox:\n\n```css\n.container {\n  display: flex;\n  flex-direction: column;\n  min-height: 100vh;\n}\n\n.header, .footer {\n  flex: 0 0 auto;\n}\n\n.main {\n  display: flex;\n  flex: 1 0 auto;\n}\n\n.content {\n  flex: 1 0 auto;\n}\n\n.nav, .ads {\n  flex: 0 0 200px;\n}\n\n.nav {\n  order: -1;\n}\n```\n\n**Variable Item Sizes with Flex Ratio**:\nThe flex property allows for sophisticated space distribution:\n\n```css\n.container {\n  display: flex;\n}\n\n.item-small {\n  flex: 1;\n}\n\n.item-medium {\n  flex: 2;\n}\n\n.item-large {\n  flex: 3;\n}\n```\n\nThis creates a layout where items take up space in a 1:2:3 ratio, regardless of container size.\n\n**Combining Flexbox and Grid**:\nFor complex layouts, combining Flexbox and Grid leverages the strengths of each:\n\n```css\n.page {\n  display: grid;\n  grid-template-rows: auto 1fr auto;\n  min-height: 100vh;\n}\n\n.main-content {\n  display: flex;\n  flex-wrap: wrap;\n  gap: 20px;\n}\n\n.card {\n  flex: 1 0 300px;\n  display: grid;\n  grid-template-rows: auto 1fr auto;\n}\n```\n\nThis approach uses Grid for the overall page structure and card layouts, while Flexbox handles the distribution of cards within the main content area.\n\n## CSS Custom Properties (Variables)\n\nCSS Custom Properties bring dynamic capabilities to CSS, enabling more maintainable, themeable, and interactive styles.\n\n### Dynamic Theming\n\nCustom properties facilitate theme switching without JavaScript:\n\n```css\n:root {\n  --primary-color: #1a73e8;\n  --secondary-color: #f1f3f4;\n  --text-color: #202124;\n  --background-color: #ffffff;\n}\n\n[data-theme=\"dark\"] {\n  --primary-color: #8ab4f8;\n  --secondary-color: #3c4043;\n  --text-color: #e8eaed;\n  --background-color: #202124;\n}\n\nbody {\n  background-color: var(--background-color);\n  color: var(--text-color);\n}\n\n.button {\n  background-color: var(--primary-color);\n  color: white;\n}\n```\n\nSwitching themes becomes as simple as changing a data attribute:\n\n```javascript\ndocument.documentElement.setAttribute('data-theme', 'dark');\n```\n\n### Responsive Design with Custom Properties\n\nCustom properties can be redefined within media queries, simplifying responsive designs:\n\n```css\n:root {\n  --container-width: 1200px;\n  --heading-size: 32px;\n  --paragraph-size: 16px;\n  --spacing-unit: 24px;\n}\n\n@media (max-width: 768px) {\n  :root {\n    --container-width: 100%;\n    --heading-size: 24px;\n    --paragraph-size: 14px;\n    --spacing-unit: 16px;\n  }\n}\n\n.container {\n  max-width: var(--container-width);\n  margin: 0 auto;\n}\n\nh1 {\n  font-size: var(--heading-size);\n  margin-bottom: var(--spacing-unit);\n}\n\np {\n  font-size: var(--paragraph-size);\n  margin-bottom: var(--spacing-unit);\n}\n```\n\n### Component-Based Architecture\n\nCustom properties enable component-based CSS architectures by scoping variables to components:\n\n```css\n.card {\n  --card-padding: 16px;\n  --card-border-radius: 8px;\n  --card-background: white;\n  \n  padding: var(--card-padding);\n  border-radius: var(--card-border-radius);\n  background-color: var(--card-background);\n  box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);\n}\n\n.card--featured {\n  --card-padding: 24px;\n  --card-border-radius: 12px;\n  --card-background: #f8f9fa;\n}\n```\n\nThis approach allows for component variations without additional CSS classes for every property change.\n\n### Calculated Values\n\nThe `calc()` function combined with custom properties enables dynamic calculations:\n\n```css\n:root {\n  --spacing-unit: 8px;\n  --container-padding: calc(var(--spacing-unit) * 3);\n  --content-width: calc(100% - (var(--container-padding) * 2));\n}\n\n.container {\n  padding: var(--container-padding);\n}\n\n.content {\n  width: var(--content-width);\n  margin: 0 auto;\n}\n```\n\n## CSS Animations and Transitions\n\nModern CSS provides powerful tools for creating smooth, performant animations and transitions.\n\n### Performance-Optimized Animations\n\nFor optimal performance, animations should primarily use properties that only affect compositing:\n\n```css\n.optimized-animation {\n  transform: translateX(0);\n  opacity: 1;\n  transition: transform 0.3s ease, opacity 0.3s ease;\n}\n\n.optimized-animation:hover {\n  transform: translateX(20px);\n  opacity: 0.8;\n}\n```\n\nUsing `transform` and `opacity` allows the browser to optimize the animation by handling it on the GPU, avoiding layout recalculations.\n\n### Keyframe Animations\n\nFor complex animations, `@keyframes` provide fine-grained control:\n\n```css\n@keyframes float {\n  0% {\n    transform: translateY(0px);\n  }\n  50% {\n    transform: translateY(-20px);\n  }\n  100% {\n    transform: translateY(0px);\n  }\n}\n\n.floating-element {\n  animation: float 3s ease-in-out infinite;\n}\n```\n\n### Animation Variables with Custom Properties\n\nCustom properties can make animations dynamic and configurable:\n\n```css\n.animated-element {\n  --animation-duration: 2s;\n  --animation-distance: 50px;\n  \n  animation: slide var(--animation-duration) ease infinite;\n}\n\n@keyframes slide {\n  0% {\n    transform: translateX(0);\n  }\n  50% {\n    transform: translateX(var(--animation-distance));\n  }\n  100% {\n    transform: translateX(0);\n  }\n}\n\n.animated-element.slow {\n  --animation-duration: 4s;\n  --animation-distance: 100px;\n}\n```\n\n### Scroll-Triggered Animations\n\nThe Intersection Observer API combined with CSS animations enables scroll-triggered effects:\n\n```css\n.fade-in {\n  opacity: 0;\n  transform: translateY(20px);\n  transition: opacity 0.6s ease, transform 0.6s ease;\n}\n\n.fade-in.visible {\n  opacity: 1;\n  transform: translateY(0);\n}\n```\n\n```javascript\nconst observer = new IntersectionObserver(entries => {\n  entries.forEach(entry => {\n    if (entry.isIntersecting) {\n      entry.target.classList.add('visible');\n    }\n  });\n}, { threshold: 0.1 });\n\ndocument.querySelectorAll('.fade-in').forEach(el => {\n  observer.observe(el);\n});\n```\n\n## CSS Preprocessors and Methodologies\n\nWhile modern CSS has reduced the need for preprocessors, they still offer valuable features for managing complex stylesheets.\n\n### Sass/SCSS Advanced Features\n\n**Mixins for Reusable Code Patterns**:\n```scss\n@mixin flex-center {\n  display: flex;\n  justify-content: center;\n  align-items: center;\n}\n\n@mixin responsive-font($min-size, $max-size, $min-width, $max-width) {\n  font-size: $min-size;\n  \n  @media (min-width: $min-width) {\n    font-size: calc(#{$min-size} + #{strip-unit($max-size - $min-size)} * ((100vw - #{$min-width}) / #{strip-unit($max-width - $min-width)}));\n  }\n  \n  @media (min-width: $max-width) {\n    font-size: $max-size;\n  }\n}\n\n.hero-title {\n  @include flex-center;\n  @include responsive-font(24px, 48px, 320px, 1200px);\n}\n```\n\n**Maps for Structured Data**:\n```scss\n$breakpoints: (\n  'small': 576px,\n  'medium': 768px,\n  'large': 992px,\n  'x-large': 1200px\n);\n\n@mixin respond-to($breakpoint) {\n  @if map-has-key($breakpoints, $breakpoint) {\n    @media (min-width: map-get($breakpoints, $breakpoint)) {\n      @content;\n    }\n  } @else {\n    @warn \"Unknown breakpoint: #{$breakpoint}\";\n  }\n}\n\n.container {\n  width: 100%;\n  \n  @include respond-to('medium') {\n    width: 720px;\n  }\n  \n  @include respond-to('large') {\n    width: 960px;\n  }\n}\n```\n\n### CSS Methodologies\n\n**BEM (Block, Element, Modifier)**:\nBEM provides a structured naming convention that clarifies the relationship between CSS classes:\n\n```css\n/* Block */\n.card {\n  background: white;\n  border-radius: 4px;\n}\n\n/* Element */\n.card__title {\n  font-size: 18px;\n  font-weight: bold;\n}\n\n.card__content {\n  padding: 16px;\n}\n\n/* Modifier */\n.card--featured {\n  background: #f8f9fa;\n  box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\n}\n```\n\n**CUBE CSS (Composition, Utility, Block, Exception)**:\nCUBE CSS combines the strengths of multiple approaches:\n\n```css\n/* Composition */\n.stack {\n  display: flex;\n  flex-direction: column;\n  gap: var(--space-s);\n}\n\n/* Utility */\n.bg-primary {\n  background-color: var(--color-primary);\n}\n\n.text-center {\n  text-align: center;\n}\n\n/* Block */\n.card {\n  padding: var(--space-m);\n  border-radius: var(--radius-s);\n}\n\n/* Exception */\n.card[data-variant='compact'] {\n  padding: var(--space-s);\n}\n```\n\n## CSS-in-JS and Scoped Styles\n\nModern web applications often use component-based architectures, leading to new approaches for styling.\n\n### CSS Modules\n\nCSS Modules scope styles to specific components by automatically generating unique class names:\n\n```css\n/* Button.module.css */\n.button {\n  padding: 8px 16px;\n  border-radius: 4px;\n  background-color: #1a73e8;\n  color: white;\n}\n\n.primary {\n  background-color: #1a73e8;\n}\n\n.secondary {\n  background-color: #5f6368;\n}\n```\n\n```jsx\nimport styles from './Button.module.css';\n\nfunction Button({ variant = 'primary', children }) {\n  return (\n    <button className={`${styles.button} ${styles[variant]}`}>\n      {children}\n    </button>\n  );\n}\n```\n\n### Styled Components\n\nStyled Components combines CSS and JavaScript, enabling dynamic styling based on props:\n\n```jsx\nimport styled from 'styled-components';\n\nconst Button = styled.button`\n  padding: 8px 16px;\n  border-radius: 4px;\n  background-color: ${props => props.primary ? '#1a73e8' : '#5f6368'};\n  color: white;\n  font-size: ${props => props.size === 'large' ? '18px' : '14px'};\n  \n  &:hover {\n    opacity: 0.9;\n  }\n`;\n\nfunction App() {\n  return (\n    <div>\n      <Button primary>Primary Button</Button>\n      <Button>Secondary Button</Button>\n      <Button primary size=\"large\">Large Primary Button</Button>\n    </div>\n  );\n}\n```\n\n## Future CSS Features\n\nSeveral upcoming CSS features promise to further enhance web styling capabilities:\n\n### Container Queries\n\nUnlike media queries that respond to viewport size, container queries respond to the size of a containing element:\n\n```css\n.card-container {\n  container-type: inline-size;\n}\n\n.card {\n  display: grid;\n  grid-template-columns: 1fr;\n}\n\n@container (min-width: 400px) {\n  .card {\n    grid-template-columns: 200px 1fr;\n  }\n}\n```\n\nThis enables truly responsive components that adapt based on their container, not just the viewport.\n\n### Cascade Layers\n\nCascade layers provide explicit control over specificity through the `@layer` rule:\n\n```css\n@layer reset, base, components, utilities;\n\n@layer reset {\n  /* Reset styles with lowest precedence */\n  * {\n    margin: 0;\n    padding: 0;\n    box-sizing: border-box;\n  }\n}\n\n@layer base {\n  /* Base styles */\n  body {\n    font-family: sans-serif;\n    line-height: 1.5;\n  }\n}\n\n@layer components {\n  /* Component styles */\n  .button {\n    padding: 8px 16px;\n    border-radius: 4px;\n  }\n}\n\n@layer utilities {\n  /* Utility styles with highest precedence */\n  .hidden {\n    display: none !important;\n  }\n}\n```\n\nThis approach solves specificity conflicts by making the layer order more important than selector specificity.\n\n### Nesting\n\nNative CSS nesting will simplify style organization without preprocessors:\n\n```css\n.card {\n  background: white;\n  border-radius: 8px;\n  \n  & .title {\n    font-size: 18px;\n    font-weight: bold;\n    \n    &:hover {\n      color: blue;\n    }\n  }\n  \n  & .content {\n    padding: 16px;\n  }\n  \n  &.featured {\n    background: #f8f9fa;\n  }\n}\n```\n\n## Conclusion\n\nAdvanced CSS techniques have transformed web styling from simple decorative properties to a sophisticated system capable of creating complex layouts, animations, and interactive experiences. Modern approaches like CSS Grid, Flexbox, Custom Properties, and optimized animations provide powerful tools for creating responsive, maintainable, and performant web interfaces.\n\nAs CSS continues to evolve with features like container queries, cascade layers, and native nesting, developers have increasingly powerful tools to create sophisticated user interfaces while maintaining clean, maintainable code. By leveraging these advanced techniques, web developers can create experiences that are both visually compelling and technically excellent.\n\nThe future of CSS lies in its ability to balance powerful features with simplicity and performance, enabling developers to create increasingly sophisticated web experiences without sacrificing the core principles that have made CSS successful for over two decades.",
    thumbnail: null,
    sourceType: "upload",
  },
  {
    id: "doc6",
    title: "JavaScript Design Patterns",
    uploadDate: "2025-05-21",
    fileType: "pdf",
    content: "# JavaScript Design Patterns\n\n## Introduction\n\nDesign patterns represent proven solutions to common software design problems, providing structured approaches to creating maintainable and scalable code. In JavaScript, a language known for its flexibility and multi-paradigm nature, design patterns are particularly valuable for managing complexity and promoting best practices.\n\nThis paper explores essential JavaScript design patterns, their implementations, use cases, and evolution in modern JavaScript development. We'll examine how these patterns solve specific problems and how they've adapted to the changing JavaScript ecosystem, including the impact of ES6+ features and modern frameworks.\n\n## Creational Patterns\n\nCreational patterns focus on object creation mechanisms, providing flexibility in what gets created, how it's created, and who creates it.\n\n### Singleton Pattern\n\nThe Singleton pattern ensures a class has only one instance and provides a global point of access to it. In JavaScript, this pattern is often implemented using closures or ES6 modules.\n\n#### Traditional Implementation\n\n```javascript\nconst Singleton = (function() {\n  let instance;\n  \n  function createInstance() {\n    const object = new Object({\n      property1: \"I am a singleton\",\n      property2: 42,\n      method1: function() {\n        return this.property1;\n      }\n    });\n    return object;\n  }\n  \n  return {\n    getInstance: function() {\n      if (!instance) {\n        instance = createInstance();\n      }\n      return instance;\n    }\n  };\n})();\n\nconst instance1 = Singleton.getInstance();\nconst instance2 = Singleton.getInstance();\nconsole.log(instance1 === instance2); // true\n```\n\n#### Modern Implementation with ES6 Modules\n\n```javascript\n// singleton.js\nclass Database {\n  constructor(data) {\n    if (Database.instance) {\n      return Database.instance;\n    }\n    \n    this.data = data;\n    Database.instance = this;\n  }\n  \n  getData() {\n    return this.data;\n  }\n  \n  setData(data) {\n    this.data = data;\n  }\n}\n\n// Export an instance, not the class\nexport default new Database('Initial data');\n```\n\n```javascript\n// usage.js\nimport database from './singleton.js';\n// Any module importing this will get the same instance\n```\n\n#### Use Cases\n\n- Database connections\n- Configuration managers\n- Logging services\n- State management in applications\n\n#### Considerations\n\nWhile singletons provide a convenient global access point, they can introduce tight coupling and make testing more difficult. In modern JavaScript applications, dependency injection and state management libraries often provide better alternatives.\n\n### Factory Pattern\n\nThe Factory pattern provides an interface for creating objects without specifying their concrete classes, allowing for flexibility in object creation.\n\n#### Implementation\n\n```javascript\n// Simple Factory\nfunction createUser(type) {\n  if (type === 'admin') {\n    return {\n      name: '',\n      permissions: ['read', 'write', 'delete'],\n      accessLevel: 'admin',\n      setName: function(name) { this.name = name; }\n    };\n  } else if (type === 'user') {\n    return {\n      name: '',\n      permissions: ['read'],\n      accessLevel: 'user',\n      setName: function(name) { this.name = name; }\n    };\n  }\n}\n\nconst adminUser = createUser('admin');\nadminUser.setName('John');\nconsole.log(adminUser); // { name: 'John', permissions: [...], accessLevel: 'admin', ... }\n```\n\n#### Factory Method Pattern\n\n```javascript\nclass UserFactory {\n  createUser(type) {\n    let user;\n    \n    if (type === 'admin') {\n      user = new AdminUser();\n    } else if (type === 'moderator') {\n      user = new ModeratorUser();\n    } else {\n      user = new RegularUser();\n    }\n    \n    user.type = type;\n    \n    return user;\n  }\n}\n\nclass AdminUser {\n  constructor() {\n    this.permissions = ['read', 'write', 'delete'];\n  }\n}\n\nclass ModeratorUser {\n  constructor() {\n    this.permissions = ['read', 'write'];\n  }\n}\n\nclass RegularUser {\n  constructor() {\n    this.permissions = ['read'];\n  }\n}\n\nconst factory = new UserFactory();\nconst admin = factory.createUser('admin');\nconsole.log(admin.permissions); // ['read', 'write', 'delete']\n```\n\n#### Use Cases\n\n- Creating UI elements based on user input\n- Implementing plugin architectures\n- Supporting multiple data sources with a consistent interface\n- Abstracting object creation in complex systems\n\n### Module Pattern\n\nThe Module pattern encapsulates private state and behavior, exposing only a public API. This pattern was widely used before ES6 modules became standard.\n\n#### Traditional Implementation\n\n```javascript\nconst Calculator = (function() {\n  // Private variables and functions\n  let result = 0;\n  \n  function add(a, b) {\n    return a + b;\n  }\n  \n  function subtract(a, b) {\n    return a - b;\n  }\n  \n  // Public API\n  return {\n    add: function(a, b) {\n      result = add(a, b);\n      return result;\n    },\n    subtract: function(a, b) {\n      result = subtract(a, b);\n      return result;\n    },\n    getResult: function() {\n      return result;\n    }\n  };\n})();\n\nconsole.log(Calculator.add(5, 3)); // 8\nconsole.log(Calculator.getResult()); // 8\n```\n\n#### Modern Implementation with ES6 Classes and Modules\n\n```javascript\n// calculator.js\nclass Calculator {\n  #result = 0; // Private field (Stage 3 proposal)\n  \n  #add(a, b) { // Private method\n    return a + b;\n  }\n  \n  #subtract(a, b) {\n    return a - b;\n  }\n  \n  add(a, b) {\n    this.#result = this.#add(a, b);\n    return this.#result;\n  }\n  \n  subtract(a, b) {\n    this.#result = this.#subtract(a, b);\n    return this.#result;\n  }\n  \n  getResult() {\n    return this.#result;\n  }\n}\n\nexport default new Calculator();\n```\n\n#### Use Cases\n\n- Organizing related functionality\n- Encapsulating implementation details\n- Creating reusable libraries\n- Managing application state\n\n## Structural Patterns\n\nStructural patterns focus on object composition, creating relationships between objects to form larger structures.\n\n### Decorator Pattern\n\nThe Decorator pattern attaches additional responsibilities to objects dynamically, providing a flexible alternative to subclassing for extending functionality.\n\n#### Implementation\n\n```javascript\n// Component interface\nclass Coffee {\n  cost() {\n    return 5;\n  }\n  \n  description() {\n    return 'Basic coffee';\n  }\n}\n\n// Decorator\nclass CoffeeDecorator {\n  constructor(coffee) {\n    this.coffee = coffee;\n  }\n  \n  cost() {\n    return this.coffee.cost();\n  }\n  \n  description() {\n    return this.coffee.description();\n  }\n}\n\n// Concrete decorators\nclass MilkDecorator extends CoffeeDecorator {\n  cost() {\n    return this.coffee.cost() + 1.5;\n  }\n  \n  description() {\n    return `${this.coffee.description()}, milk`;\n  }\n}\n\nclass CaramelDecorator extends CoffeeDecorator {\n  cost() {\n    return this.coffee.cost() + 2;\n  }\n  \n  description() {\n    return `${this.coffee.description()}, caramel`;\n  }\n}\n\n// Usage\nlet coffee = new Coffee();\ncoffee = new MilkDecorator(coffee);\ncoffee = new CaramelDecorator(coffee);\n\nconsole.log(coffee.description()); // \"Basic coffee, milk, caramel\"\nconsole.log(coffee.cost()); // 8.5\n```\n\n#### Functional Implementation\n\n```javascript\nfunction coffee() {\n  return {\n    cost: () => 5,\n    description: () => 'Basic coffee'\n  };\n}\n\nfunction withMilk(coffee) {\n  const cost = coffee.cost();\n  const description = coffee.description();\n  \n  return {\n    cost: () => cost + 1.5,\n    description: () => `${description}, milk`\n  };\n}\n\nfunction withCaramel(coffee) {\n  const cost = coffee.cost();\n  const description = coffee.description();\n  \n  return {\n    cost: () => cost + 2,\n    description: () => `${description}, caramel`\n  };\n}\n\n// Usage\nconst myCoffee = withCaramel(withMilk(coffee()));\nconsole.log(myCoffee.description()); // \"Basic coffee, milk, caramel\"\nconsole.log(myCoffee.cost()); // 8.5\n```\n\n#### Use Cases\n\n- Adding features to objects without modifying their structure\n- Implementing cross-cutting concerns like logging or caching\n- Building configurable objects with multiple optional features\n- Extending functionality in libraries without modifying source code\n\n### Adapter Pattern\n\nThe Adapter pattern allows objects with incompatible interfaces to work together by wrapping an object in an adapter that conforms to another object's interface.\n\n#### Implementation\n\n```javascript\n// Existing interface\nclass OldCalculator {\n  operate(a, b, operation) {\n    switch(operation) {\n      case 'add':\n        return a + b;\n      case 'sub':\n        return a - b;\n      default:\n        return NaN;\n    }\n  }\n}\n\n// New interface\nclass NewCalculator {\n  add(a, b) {\n    return a + b;\n  }\n  \n  subtract(a, b) {\n    return a - b;\n  }\n  \n  multiply(a, b) {\n    return a * b;\n  }\n}\n\n// Adapter\nclass CalculatorAdapter {\n  constructor() {\n    this.calculator = new NewCalculator();\n  }\n  \n  operate(a, b, operation) {\n    switch(operation) {\n      case 'add':\n        return this.calculator.add(a, b);\n      case 'sub':\n        return this.calculator.subtract(a, b);\n      case 'multiply':\n        return this.calculator.multiply(a, b);\n      default:\n        return NaN;\n    }\n  }\n}\n\n// Client code expects the old interface\nfunction calculateWithOldSystem(calculator, a, b, operation) {\n  return calculator.operate(a, b, operation);\n}\n\n// Using the adapter\nconst adapter = new CalculatorAdapter();\nconsole.log(calculateWithOldSystem(adapter, 10, 5, 'add')); // 15\nconsole.log(calculateWithOldSystem(adapter, 10, 5, 'multiply')); // 50\n```\n\n#### Use Cases\n\n- Integrating new libraries with existing code\n- Working with third-party APIs\n- Creating backward compatibility\n- Standardizing interfaces across different implementations\n\n### Proxy Pattern\n\nThe Proxy pattern provides a surrogate or placeholder for another object to control access to it, adding a level of indirection.\n\n#### Implementation\n\n```javascript\n// Target object\nclass DatabaseAccess {\n  getData() {\n    return 'Sensitive data from the database';\n  }\n  \n  setData(data) {\n    console.log(`Data saved: ${data}`);\n    return true;\n  }\n}\n\n// Proxy\nclass SecureDatabase {\n  constructor(user) {\n    this.user = user;\n    this.database = new DatabaseAccess();\n  }\n  \n  getData() {\n    if (this.user.isAuthenticated) {\n      return this.database.getData();\n    } else {\n      return 'Access denied: Authentication required';\n    }\n  }\n  \n  setData(data) {\n    if (this.user.isAuthenticated && this.user.hasWriteAccess) {\n      return this.database.setData(data);\n    } else {\n      console.log('Access denied: Write permission required');\n      return false;\n    }\n  }\n}\n\n// Usage\nconst user = {\n  isAuthenticated: true,\n  hasWriteAccess: false\n};\n\nconst database = new SecureDatabase(user);\nconsole.log(database.getData()); // \"Sensitive data from the database\"\nconsole.log(database.setData('New data')); // \"Access denied: Write permission required\", false\n```\n\n#### ES6 Proxy Implementation\n\n```javascript\nconst user = {\n  isAuthenticated: true,\n  hasWriteAccess: false\n};\n\nconst database = {\n  getData() {\n    return 'Sensitive data from the database';\n  },\n  \n  setData(data) {\n    console.log(`Data saved: ${data}`);\n    return true;\n  }\n};\n\nconst secureDatabase = new Proxy(database, {\n  get(target, property, receiver) {\n    if (property === 'getData') {\n      return function() {\n        if (user.isAuthenticated) {\n          return target.getData();\n        } else {\n          return 'Access denied: Authentication required';\n        }\n      };\n    } else if (property === 'setData') {\n      return function(data) {\n        if (user.isAuthenticated && user.hasWriteAccess) {\n          return target.setData(data);\n        } else {\n          console.log('Access denied: Write permission required');\n          return false;\n        }\n      };\n    }\n    \n    return Reflect.get(target, property, receiver);\n  }\n});\n\nconsole.log(secureDatabase.getData()); // \"Sensitive data from the database\"\nconsole.log(secureDatabase.setData('New data')); // \"Access denied: Write permission required\", false\n```\n\n#### Use Cases\n\n- Access control and validation\n- Lazy initialization of expensive resources\n- Logging and monitoring\n- Caching results of expensive operations\n- Remote proxy for accessing resources in different contexts\n\n## Behavioral Patterns\n\nBehavioral patterns focus on communication between objects, defining how they interact and distribute responsibility.\n\n### Observer Pattern\n\nThe Observer pattern defines a one-to-many dependency between objects, where multiple observers are notified of changes to the observed subject.\n\n#### Implementation\n\n```javascript\nclass Subject {\n  constructor() {\n    this.observers = [];\n  }\n  \n  subscribe(observer) {\n    this.observers.push(observer);\n  }\n  \n  unsubscribe(observer) {\n    this.observers = this.observers.filter(obs => obs !== observer);\n  }\n  \n  notify(data) {\n    this.observers.forEach(observer => observer.update(data));\n  }\n}\n\nclass Observer {\n  constructor(name) {\n    this.name = name;\n  }\n  \n  update(data) {\n    console.log(`${this.name} received update: ${data}`);\n  }\n}\n\n// Usage\nconst subject = new Subject();\nconst observer1 = new Observer('Observer 1');\nconst observer2 = new Observer('Observer 2');\n\nsubject.subscribe(observer1);\nsubject.subscribe(observer2);\n\nsubject.notify('Hello observers!');\n// Observer 1 received update: Hello observers!\n// Observer 2 received update: Hello observers!\n\nsubject.unsubscribe(observer1);\nsubject.notify('Hello again!');\n// Observer 2 received update: Hello again!\n```\n\n#### Event Emitter Implementation\n\n```javascript\nclass EventEmitter {\n  constructor() {\n    this.events = {};\n  }\n  \n  on(event, listener) {\n    if (!this.events[event]) {\n      this.events[event] = [];\n    }\n    this.events[event].push(listener);\n  }\n  \n  off(event, listener) {\n    if (!this.events[event]) return;\n    this.events[event] = this.events[event].filter(l => l !== listener);\n  }\n  \n  emit(event, ...args) {\n    if (!this.events[event]) return;\n    this.events[event].forEach(listener => listener(...args));\n  }\n  \n  once(event, listener) {\n    const onceListener = (...args) => {\n      listener(...args);\n      this.off(event, onceListener);\n    };\n    this.on(event, onceListener);\n  }\n}\n\n// Usage\nconst emitter = new EventEmitter();\n\nfunction handleUserCreated(user) {\n  console.log(`New user created: ${user.name}`);\n}\n\nemitter.on('userCreated', handleUserCreated);\nemitter.emit('userCreated', { name: 'John Doe' });\n// New user created: John Doe\n```\n\n#### Use Cases\n\n- Event handling systems\n- Implementing publish/subscribe architectures\n- UI components that respond to data changes\n- Real-time data updates and notifications\n- Decoupling systems by removing direct dependencies\n\n### Strategy Pattern\n\nThe Strategy pattern defines a family of algorithms, encapsulates each one, and makes them interchangeable, allowing the algorithm to vary independently from clients that use it.\n\n#### Implementation\n\n```javascript\n// Strategy interface\nclass SortStrategy {\n  sort(dataset) {\n    throw new Error('sort method must be implemented');\n  }\n}\n\n// Concrete strategies\nclass BubbleSortStrategy extends SortStrategy {\n  sort(dataset) {\n    console.log('Sorting using bubble sort');\n    // Implementation of bubble sort\n    return [...dataset].sort((a, b) => a - b);\n  }\n}\n\nclass QuickSortStrategy extends SortStrategy {\n  sort(dataset) {\n    console.log('Sorting using quick sort');\n    // Implementation of quick sort\n    return [...dataset].sort((a, b) => a - b);\n  }\n}\n\nclass MergeSortStrategy extends SortStrategy {\n  sort(dataset) {\n    console.log('Sorting using merge sort');\n    // Implementation of merge sort\n    return [...dataset].sort((a, b) => a - b);\n  }\n}\n\n// Context\nclass Sorter {\n  constructor(strategy) {\n    this.strategy = strategy;\n  }\n  \n  setStrategy(strategy) {\n    this.strategy = strategy;\n  }\n  \n  sort(dataset) {\n    return this.strategy.sort(dataset);\n  }\n}\n\n// Usage\nconst dataset = [1, 5, 3, 9, 2, 6];\nconst sorter = new Sorter(new BubbleSortStrategy());\n\nconsole.log(sorter.sort(dataset)); // Sorting using bubble sort, [1, 2, 3, 5, 6, 9]\n\nsorter.setStrategy(new QuickSortStrategy());\nconsole.log(sorter.sort(dataset)); // Sorting using quick sort, [1, 2, 3, 5, 6, 9]\n```\n\n#### Functional Implementation\n\n```javascript\n// Strategies as functions\nconst bubbleSort = dataset => {\n  console.log('Sorting using bubble sort');\n  return [...dataset].sort((a, b) => a - b);\n};\n\nconst quickSort = dataset => {\n  console.log('Sorting using quick sort');\n  return [...dataset].sort((a, b) => a - b);\n};\n\nconst mergeSort = dataset => {\n  console.log('Sorting using merge sort');\n  return [...dataset].sort((a, b) => a - b);\n};\n\n// Context as a function\nconst createSorter = (strategy) => ({\n  sort: dataset => strategy(dataset),\n  setStrategy: newStrategy => createSorter(newStrategy)\n});\n\n// Usage\nconst dataset = [1, 5, 3, 9, 2, 6];\nlet sorter = createSorter(bubbleSort);\n\nconsole.log(sorter.sort(dataset)); // Sorting using bubble sort, [1, 2, 3, 5, 6, 9]\n\nsorter = sorter.setStrategy(quickSort);\nconsole.log(sorter.sort(dataset)); // Sorting using quick sort, [1, 2, 3, 5, 6, 9]\n```\n\n#### Use Cases\n\n- Implementing different algorithms for the same task\n- Configuring behavior at runtime\n- Isolating algorithm implementation details from client code\n- Supporting multiple business rules or policies\n\n### Command Pattern\n\nThe Command pattern encapsulates a request as an object, allowing for parameterization of clients with different requests, queuing of requests, and logging of operations.\n\n#### Implementation\n\n```javascript\n// Command interface\nclass Command {\n  execute() {\n    throw new Error('execute method must be implemented');\n  }\n  \n  undo() {\n    throw new Error('undo method must be implemented');\n  }\n}\n\n// Concrete commands\nclass AddTextCommand extends Command {\n  constructor(editor, text) {\n    super();\n    this.editor = editor;\n    this.text = text;\n    this.previousContent = null;\n  }\n  \n  execute() {\n    this.previousContent = this.editor.getContent();\n    this.editor.addText(this.text);\n  }\n  \n  undo() {\n    if (this.previousContent !== null) {\n      this.editor.setContent(this.previousContent);\n    }\n  }\n}\n\nclass DeleteTextCommand extends Command {\n  constructor(editor, startPosition, endPosition) {\n    super();\n    this.editor = editor;\n    this.startPosition = startPosition;\n    this.endPosition = endPosition;\n    this.deletedText = null;\n    this.previousContent = null;\n  }\n  \n  execute() {\n    this.previousContent = this.editor.getContent();\n    this.deletedText = this.editor.deleteText(this.startPosition, this.endPosition);\n  }\n  \n  undo() {\n    if (this.previousContent !== null) {\n      this.editor.setContent(this.previousContent);\n    }\n  }\n}\n\n// Receiver\nclass TextEditor {\n  constructor() {\n    this.content = '';\n  }\n  \n  addText(text) {\n    this.content += text;\n  }\n  \n  deleteText(startPosition, endPosition) {\n    const deletedText = this.content.substring(startPosition, endPosition);\n    this.content = this.content.substring(0, startPosition) + this.content.substring(endPosition);\n    return deletedText;\n  }\n  \n  getContent() {\n    return this.content;\n  }\n  \n  setContent(content) {\n    this.content = content;\n  }\n}\n\n// Invoker\nclass CommandManager {\n  constructor() {\n    this.commands = [];\n    this.currentIndex = -1;\n  }\n  \n  executeCommand(command) {\n    // Remove any commands that were undone\n    if (this.currentIndex < this.commands.length - 1) {\n      this.commands = this.commands.slice(0, this.currentIndex + 1);\n    }\n    \n    command.execute();\n    this.commands.push(command);\n    this.currentIndex++;\n  }\n  \n  undo() {\n    if (this.currentIndex >= 0) {\n      const command = this.commands[this.currentIndex];\n      command.undo();\n      this.currentIndex--;\n      return true;\n    }\n    return false;\n  }\n  \n  redo() {\n    if (this.currentIndex < this.commands.length - 1) {\n      this.currentIndex++;\n      const command = this.commands[this.currentIndex];\n      command.execute();\n      return true;\n    }\n    return false;\n  }\n}\n\n// Usage\nconst editor = new TextEditor();\nconst commandManager = new CommandManager();\n\n// Execute commands\ncommandManager.executeCommand(new AddTextCommand(editor, 'Hello, '));\nconsole.log(editor.getContent()); // \"Hello, \"\n\ncommandManager.executeCommand(new AddTextCommand(editor, 'world!'));\nconsole.log(editor.getContent()); // \"Hello, world!\"\n\ncommandManager.executeCommand(new DeleteTextCommand(editor, 7, 12));\nconsole.log(editor.getContent()); // \"Hello, !\"\n\n// Undo\ncommandManager.undo();\nconsole.log(editor.getContent()); // \"Hello, world!\"\n\ncommandManager.undo();\nconsole.log(editor.getContent()); // \"Hello, \"\n\n// Redo\ncommandManager.redo();\nconsole.log(editor.getContent()); // \"Hello, world!\"\n```\n\n#### Use Cases\n\n- Implementing undo/redo functionality\n- Queueing and executing requests at different times\n- Supporting transaction-like behavior\n- Parameterizing objects with operations\n- Implementing callback functions and event handlers\n\n## Modern JavaScript and Design Patterns\n\nModern JavaScript features have influenced how design patterns are implemented, often simplifying code and providing native alternatives to traditional patterns.\n\n### Impact of ES6+ Features\n\n**Classes and Inheritance**:\nES6 classes provide a cleaner syntax for implementing patterns that involve inheritance, such as Factory Method and Decorator.\n\n**Modules**:\nNative ES modules reduce the need for the Module pattern, providing built-in encapsulation and dependency management.\n\n**Arrow Functions**:\nArrow functions simplify callback-heavy patterns like Observer and Command by preserving the lexical `this`.\n\n**Destructuring and Default Parameters**:\nThese features simplify configuration objects and parameter handling in patterns like Builder and Factory.\n\n**Proxies and Reflect**:\nThe Proxy API provides a powerful way to implement patterns like Proxy, Decorator, and Observer with less boilerplate.\n\n**Promises and Async/Await**:\nThese features transform how asynchronous patterns are implemented, replacing callback-based approaches with more readable, chainable code.\n\n### Functional Programming Influence\n\nThe rise of functional programming in JavaScript has led to more declarative implementations of design patterns:\n\n**Higher-Order Functions**:\nFunctions that take or return other functions enable elegant implementations of patterns like Decorator, Strategy, and Command.\n\n**Pure Functions**:\nEmphasizing pure functions (no side effects) leads to more predictable and testable implementations of patterns.\n\n**Immutability**:\nWorking with immutable data structures influences how state is managed in patterns like Command and Memento.\n\n**Function Composition**:\nComposing functions provides an alternative to object composition in patterns like Decorator and Chain of Responsibility.\n\n### Example: Modern Factory Pattern\n\n```javascript\n// Product types\nconst USER_TYPES = {\n  ADMIN: 'admin',\n  MODERATOR: 'moderator',\n  REGULAR: 'regular'\n};\n\n// Base user factory function\nconst createUser = ({ name, email, type = USER_TYPES.REGULAR }) => ({\n  name,\n  email,\n  type,\n  createdAt: new Date()\n});\n\n// Specialized factory functions\nconst createAdminUser = (userData) => ({\n  ...createUser({ ...userData, type: USER_TYPES.ADMIN }),\n  permissions: ['read', 'write', 'delete', 'manage-users'],\n  isAdmin: true\n});\n\nconst createModeratorUser = (userData) => ({\n  ...createUser({ ...userData, type: USER_TYPES.MODERATOR }),\n  permissions: ['read', 'write', 'delete'],\n  isModerator: true\n});\n\n// Factory function that delegates to specialized factories\nconst userFactory = (userData) => {\n  switch (userData.type) {\n    case USER_TYPES.ADMIN:\n      return createAdminUser(userData);\n    case USER_TYPES.MODERATOR:\n      return createModeratorUser(userData);\n    default:\n      return createUser(userData);\n  }\n};\n\n// Usage\nconst admin = userFactory({\n  name: 'Admin User',\n  email: 'admin@example.com',\n  type: USER_TYPES.ADMIN\n});\n\nconsole.log(admin);\n// {\n//   name: 'Admin User',\n//   email: 'admin@example.com',\n//   type: 'admin',\n//   createdAt: [Date object],\n//   permissions: ['read', 'write', 'delete', 'manage-users'],\n//   isAdmin: true\n// }\n```\n\n### Example: Modern Observer Pattern with RxJS\n\n```javascript\nimport { Subject } from 'rxjs';\nimport { filter, map } from 'rxjs/operators';\n\n// Create a subject (observable and observer)\nconst userEvents = new Subject();\n\n// Subscribe to all events\nconst allEventsSubscription = userEvents.subscribe(\n  event => console.log(`All events: ${event.type}`, event.data)\n);\n\n// Subscribe only to login events\nconst loginSubscription = userEvents.pipe(\n  filter(event => event.type === 'LOGIN'),\n  map(event => event.data.user)\n).subscribe(\n  user => console.log(`User logged in: ${user.name}`)\n);\n\n// Emit events\nuserEvents.next({\n  type: 'LOGIN',\n  data: { user: { name: 'John', id: 123 } }\n});\n\nuserEvents.next({\n  type: 'LOGOUT',\n  data: { userId: 123 }\n});\n\n// Clean up\nallEventsSubscription.unsubscribe();\nloginSubscription.unsubscribe();\n```\n\n## Design Patterns in Modern Frameworks\n\nModern JavaScript frameworks incorporate design patterns into their core architecture, often providing built-in implementations or alternatives.\n\n### React\n\n**Component Pattern**:\nReact components encapsulate UI and behavior, similar to the Composite pattern.\n\n**Higher-Order Components (HOCs)**:\nHOCs implement the Decorator pattern, enhancing components with additional functionality.\n\n**Render Props**:\nThe render props pattern provides an alternative to HOCs for sharing behavior between components.\n\n**Context API**:\nReact's Context API implements a variation of the Observer pattern for state management.\n\n**Hooks**:\nHooks like useState and useEffect provide a functional approach to stateful logic, replacing class-based patterns.\n\n### Vue.js\n\n**Component System**:\nVue components combine templates, scripts, and styles, implementing a variation of the Composite pattern.\n\n**Mixins**:\nVue mixins implement the Decorator pattern for sharing component functionality.\n\n**Vuex**:\nVuex implements a centralized state management pattern inspired by Flux and Redux.\n\n**Computed Properties**:\nVue's computed properties implement a form of the Memoization pattern.\n\n### Angular\n\n**Dependency Injection**:\nAngular's DI system is a core architectural pattern for managing component dependencies.\n\n**Services**:\nAngular services often implement the Singleton pattern for shared functionality.\n\n**Directives**:\nDirectives implement the Decorator pattern by adding behavior to DOM elements.\n\n**RxJS Integration**:\nAngular's integration with RxJS leverages the Observer pattern for reactive programming.\n\n## Conclusion\n\nDesign patterns remain a fundamental tool in JavaScript development, providing structured approaches to common problems. While the implementation details have evolved with modern JavaScript features and frameworks, the core principles behind these patterns continue to guide effective software design.\n\nThe most significant shift in recent years has been toward more functional and declarative implementations, leveraging JavaScript's flexibility to create cleaner, more maintainable code. Modern frameworks have also incorporated many patterns into their core architecture, providing developers with built-in solutions to common design challenges.\n\nAs JavaScript continues to evolve, design patterns will adapt to new language features and paradigms, but their essential role in managing complexity and promoting best practices will remain unchanged. Understanding these patterns—both in their traditional and modern forms—equips developers with a powerful toolkit for creating robust, maintainable JavaScript applications.",
    thumbnail: null,
    sourceType: "upload",
  },
  {
    id: "doc7",
    title: "臺北最佳街頭美食指南",
    uploadDate: "2025-05-30",
    fileType: "pdf",
    content: "# 臺北最佳街頭美食指南\n\n## 前言\n\n臺北市作為臺灣的首都，不僅是政治和經濟中心，更是一座充滿活力的美食天堂。在這座城市的大街小巷中，隱藏著無數令人垂涎的街頭美食，從傳統小吃到創新料理，應有盡有。本指南將帶您探索臺北最具特色的街頭美食，讓您在這座城市的美食之旅中，品嚐到最道地的臺灣風味。\n\n## 夜市美食：臺北美食文化的縮影\n\n### 士林夜市\n\n士林夜市是臺北最著名的夜市之一，也是遊客必訪的美食勝地。這裡的美食種類繁多，從傳統小吃到創新料理，應有盡有。\n\n#### 必嚐美食：\n\n1. **大餅包小餅**：外層是酥脆的餅皮，內層包裹著多種食材，如雞肉、蔬菜和特製醬料，口感豐富，風味獨特。\n\n2. **士林大香腸**：臺灣特色小吃，外皮酥脆，內餡多汁，搭配蒜頭和酸菜，風味絕佳。\n\n3. **生炒花枝**：新鮮的花枝（魷魚）與各種蔬菜一起快炒，保留了花枝的鮮甜和脆嫩，是夜市中的人氣美食。\n\n4. **藥燉排骨**：將豬排骨與中藥材一起燉煮，湯頭濃郁，肉質軟嫩，既美味又滋補。\n\n5. **士林豪大大雞排**：超大尺寸的雞排，外酥內嫩，調味獨特，是夜市中最受歡迎的小吃之一。\n\n### 寧夏夜市\n\n寧夏夜市位於臺北市大同區，以傳統臺灣小吃聞名，是品嚐道地臺灣美食的絕佳去處。\n\n#### 必嚐美食：\n\n1. **臺灣鹹酥雞**：將雞肉切成小塊，裹上特製的粉漿後油炸，外酥內嫩，調味豐富，是臺灣最受歡迎的宵夜小吃。\n\n2. **蚵仔煎**：將新鮮的蚵仔與蛋液、地瓜粉一起煎製，淋上特製醬料，鮮美可口。\n\n3. **麻油雞**：將雞肉與麻油、薑片一起燉煮，湯頭香濃，肉質鮮嫩，是臺灣傳統的進補美食。\n\n4. **臭豆腐**：外酥內嫩的豆腐，搭配特製的醬料和泡菜，雖然氣味特殊，但味道絕佳，是臺灣特色小吃。\n\n5. **胡椒餅**：外皮酥脆，內餡是多汁的豬肉和蔥花，加入大量的黑胡椒調味，香氣四溢，是寧夏夜市的招牌美食。\n\n### 饒河街夜市\n\n饒河街夜市位於臺北市松山區，是臺北東區最大的夜市，以多樣化的美食和商品聞名。\n\n#### 必嚐美食：\n\n1. **蚵仔麵線**：將新鮮的蚵仔與細麵線一起煮熟，加入特製的醬料和香菜，鮮美滑順，是臺灣傳統小吃。\n\n2. **藥燉排骨**：將豬排骨與中藥材一起燉煮，湯頭濃郁，肉質軟嫩，既美味又滋補。\n\n3. **臺灣鹹酥雞**：將雞肉切成小塊，裹上特製的粉漿後油炸，外酥內嫩，調味豐富，是臺灣最受歡迎的宵夜小吃。\n\n4. **胡椒餅**：外皮酥脆，內餡是多汁的豬肉和蔥花，加入大量的黑胡椒調味，香氣四溢。\n\n5. **臭豆腐**：外酥內嫩的豆腐，搭配特製的醬料和泡菜，雖然氣味特殊，但味道絕佳，是臺灣特色小吃。\n\n## 早餐美食：開啟美好一天的能量來源\n\n### 傳統早餐店\n\n臺灣的傳統早餐店提供多種美味的早餐選擇，是當地人開始一天的能量來源。\n\n#### 必嚐美食：\n\n1. **蛋餅**：將麵糊倒入平底鍋中煎成薄餅，加入蛋液和各種配料，如火腿、起司、蔬菜等，捲起來食用，是臺灣最受歡迎的早餐之一。\n\n2. **油條**：將麵糰揉成長條狀，油炸至金黃酥脆，外酥內軟，可以搭配豆漿或稀飯食用。\n\n3. **豆漿**：新鮮的黃豆磨成漿後煮熟，可以選擇甜豆漿或鹹豆漿，是臺灣傳統的早餐飲品。\n\n4. **飯糰**：將飯團成橢圓形，內餡包括各種食材，如肉鬆、鹹蛋、醃製蘿蔔等，外層包裹著海苔，方便攜帶和食用。\n\n5. **燒餅油條**：將油條包在燒餅中，外層酥脆，內層軟嫩，是臺灣傳統的早餐組合。\n\n### 永和豆漿\n\n永和豆漿是臺北著名的早餐店，以新鮮的豆漿和多種傳統早餐聞名。\n\n#### 必嚐美食：\n\n1. **鹹豆漿**：將豆漿加入醋、蔥花、油條等食材，形成獨特的鹹味，是臺灣特色的早餐飲品。\n\n2. **蔥油餅**：將麵糰揉成薄餅，加入蔥花和油脂，煎至金黃酥脆，外酥內軟，風味獨特。\n\n3. **燒餅油條**：將油條包在燒餅中，外層酥脆，內層軟嫩，是臺灣傳統的早餐組合。\n\n4. **小籠包**：薄皮包裹著多汁的豬肉餡，蒸熟後皮薄餡多，湯汁豐富，是早餐的美味選擇。\n\n5. **蛋餅**：將麵糊倒入平底鍋中煎成薄餅，加入蛋液和各種配料，如火腿、起司、蔬菜等，捲起來食用，是臺灣最受歡迎的早餐之一。\n\n## 小吃店：隱藏在巷弄中的美食寶藏\n\n### 鼎泰豐\n\n鼎泰豐是臺北最著名的小籠包餐廳，也是米其林星級餐廳，以精緻的小籠包和多種點心聞名。\n\n#### 必嚐美食：\n\n1. **小籠包**：薄皮包裹著多汁的豬肉餡，蒸熟後皮薄餡多，湯汁豐富，是鼎泰豐的招牌美食。\n\n2. **蝦仁燒賣**：將新鮮的蝦仁和豬肉餡包在薄皮中，蒸熟後鮮美可口，是鼎泰豐的特色點心。\n\n3. **雞湯麵**：清淡的雞湯配上細麵條，湯頭鮮美，麵條彈牙，是鼎泰豐的招牌麵食。\n\n4. **炒飯**：將米飯與各種食材一起炒製，口感鬆軟，風味獨特，是鼎泰豐的人氣主食。\n\n5. **紅豆湯圓**：將紅豆煮成甜湯，加入軟糯的湯圓，甜而不膩，是鼎泰豐的招牌甜點。\n\n### 阜杭豆漿\n\n阜杭豆漿是臺北著名的早餐店，以新鮮的豆漿和多種傳統早餐聞名，每天都有大量的顧客排隊等候。\n\n#### 必嚐美食：\n\n1. **燒餅油條**：將油條包在燒餅中，外層酥脆，內層軟嫩，是臺灣傳統的早餐組合。\n\n2. **甜豆漿**：新鮮的黃豆磨成漿後煮熟，加入糖調味，清甜可口，是臺灣傳統的早餐飲品。\n\n3. **鹹豆漿**：將豆漿加入醋、蔥花、油條等食材，形成獨特的鹹味，是臺灣特色的早餐飲品。\n\n4. **蛋餅**：將麵糊倒入平底鍋中煎成薄餅，加入蛋液和各種配料，如火腿、起司、蔬菜等，捲起來食用，是臺灣最受歡迎的早餐之一。\n\n5. **燒餅夾蛋**：將煎蛋夾在燒餅中，外酥內軟，風味獨特，是阜杭豆漿的特色早餐。\n\n### 林東芳牛肉麵\n\n林東芳牛肉麵是臺北著名的牛肉麵店，以濃郁的湯頭和軟嫩的牛肉聞名，是品嚐臺灣傳統牛肉麵的絕佳去處。\n\n#### 必嚐美食：\n\n1. **紅燒牛肉麵**：將牛肉與多種香料一起燉煮，湯頭濃郁，肉質軟嫩，是臺灣最受歡迎的麵食之一。\n\n2. **清燉牛肉麵**：以清湯為基底，湯頭清淡但鮮美，牛肉軟嫩，是喜愛清淡口味的人的絕佳選擇。\n\n3. **牛肉餃子**：將牛肉餡包在薄皮中，煮熟後鮮美可口，是牛肉麵的絕佳配菜。\n\n4. **牛筋麵**：將牛筋與牛肉一起燉煮，口感獨特，風味絕佳，是牛肉麵的變化版本。\n\n5. **牛雜湯**：將各種牛雜與香料一起燉煮，湯頭濃郁，口感豐富，是牛肉麵店的特色湯品。\n\n## 創新街頭美食：傳統與現代的完美結合\n\n### 臺北創意市集\n\n臺北的創意市集是年輕創業者展示創新美食的平台，這裡可以品嚐到傳統與現代結合的創意料理。\n\n#### 必嚐美食：\n\n1. **創意蔥油餅**：將傳統的蔥油餅加入各種創新配料，如起司、培根、蔬菜等，創造出新的風味。\n\n2. **創意臭豆腐**：將傳統的臭豆腐與各種創新醬料結合，如麻辣醬、起司醬等，創造出新的口味。\n\n3. **創意珍珠奶茶**：將傳統的珍珠奶茶與各種創新配料結合，如水果、巧克力等，創造出新的風味。\n\n4. **創意蛋餅**：將傳統的蛋餅與各種創新配料結合，如墨西哥辣椒、泰式酸辣等，創造出國際風味。\n\n5. **創意冰品**：將傳統的臺灣冰品與各種創新配料結合，如抹茶、巧克力等，創造出新的口味。\n\n### 臺北國際美食展\n\n臺北國際美食展是展示臺灣和國際美食的大型活動，這裡可以品嚐到來自世界各地的美食，以及臺灣本土的創新料理。\n\n#### 必嚐美食：\n\n1. **國際風味小吃**：來自世界各地的特色小吃，如日本壽司、韓國炸雞、泰國炒河粉等，讓您在臺北就能環遊世界。\n\n2. **創新臺灣小吃**：將傳統的臺灣小吃與國際風味結合，創造出獨特的創新料理。\n\n3. **特色甜點**：來自世界各地的特色甜點，如法國馬卡龍、義大利提拉米蘇、日本和菓子等，滿足您的甜點慾望。\n\n4. **創意飲品**：將傳統的臺灣飲品與國際風味結合，創造出獨特的創意飲品。\n\n5. **健康美食**：注重健康和營養的創新料理，如有機蔬食、低脂料理等，讓您在享受美食的同時也能保持健康。\n\n## 飲品文化：臺北特色飲品\n\n### 珍珠奶茶\n\n珍珠奶茶是臺灣最著名的飲品之一，也是臺灣飲品文化的代表。在臺北，您可以找到各種風味的珍珠奶茶，從傳統到創新，應有盡有。\n\n#### 必嚐飲品：\n\n1. **傳統珍珠奶茶**：將紅茶與奶精混合，加入珍珠（粉圓），是臺灣最經典的飲品。\n\n2. **手搖珍珠奶茶**：由專業的手搖飲料店製作，可以根據個人喜好調整甜度和冰量，是臺灣年輕人最喜愛的飲品。\n\n3. **創意珍珠奶茶**：將傳統的珍珠奶茶與各種創新配料結合，如水果、巧克力等，創造出新的風味。\n\n4. **健康珍珠奶茶**：使用低糖、低脂的配料，讓您在享受美味的同時也能保持健康。\n\n5. **季節限定珍珠奶茶**：根據季節推出的特色珍珠奶茶，如夏季的水果珍珠奶茶、冬季的薑汁珍珠奶茶等。\n\n### 手搖飲料店\n\n手搖飲料店是臺灣特色的飲品店，提供各種新鮮製作的飲品，是臺灣人日常生活中不可或缺的一部分。\n\n#### 必嚐飲品：\n\n1. **水果茶**：將新鮮的水果與茶葉一起沖泡，清爽可口，是夏季的熱門飲品。\n\n2. **奶蓋茶**：在茶上加入一層奶蓋，口感豐富，風味獨特，是近年來流行的創新飲品。\n\n3. **青茶**：使用臺灣特產的青茶葉沖泡，香氣清新，口感甘醇，是臺灣傳統的茶飲。\n\n4. **冬瓜茶**：將冬瓜與糖一起熬煮，清涼解渴，是臺灣傳統的夏季飲品。\n\n5. **創意調飲**：將各種飲料和配料創意組合，如檸檬綠茶、芒果冰沙等，是手搖飲料店的特色。\n\n## 結語\n\n臺北的街頭美食文化豐富多彩，從傳統小吃到創新料理，從早餐店到夜市，從小吃店到創意市集，每一處都有獨特的風味等待您的探索。希望本指南能幫助您在臺北的美食之旅中，品嚐到最道地的臺灣風味，體驗臺北的美食文化。無論您是美食愛好者還是旅遊者，臺北的街頭美食都將為您帶來難忘的味覺體驗。祝您在臺北的美食之旅中，收穫滿滿的美食記憶！",
    thumbnail: null,
    sourceType: "upload",
  }
];

export default mockDocuments;
